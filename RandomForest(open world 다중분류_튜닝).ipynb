{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23956,"status":"ok","timestamp":1732844854316,"user":{"displayName":"오윤재","userId":"04375251631092764589"},"user_tz":-540},"id":"LQhjHppc9pJR","outputId":"3c99df7d-1051-4dcc-b5f7-34513c4aed42"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KtOOy0ZsXHAz"},"outputs":[],"source":["import pandas as pd\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ChMhlMzyXe1S"},"outputs":[],"source":["data=pd.read_csv('/content/drive/MyDrive/monunmon.csv')"]},{"cell_type":"markdown","metadata":{"id":"wDy0xdi-ZDUU"},"source":["# 배깅- Random Forest"]},{"cell_type":"markdown","metadata":{"id":"IZTqcVXya0uT"},"source":["- 기본 모델 학습"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"jDhxA60F8Ukt","outputId":"192aa342-546a-4197-fd6f-078c745824d3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 3 folds for each of 216 candidates, totalling 648 fits\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Best Parameters: {'bootstrap': False, 'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n","Best F1 Score (weighted): 0.7407923378900692\n","Accuracy: 0.7511363636363636\n","F1 Score (weighted): 0.7513035293770451\n","\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","          -1       0.59      0.69      0.64       590\n","           0       0.63      0.63      0.63        30\n","           1       0.68      0.61      0.64        44\n","           2       0.86      0.78      0.82        41\n","           3       0.77      0.70      0.73        33\n","           4       0.68      0.81      0.74        32\n","           5       0.80      0.89      0.85        37\n","           6       0.86      0.95      0.90        38\n","           7       0.90      0.77      0.83        35\n","           8       0.71      0.82      0.76        33\n","           9       0.73      0.73      0.73        26\n","          10       0.84      0.74      0.79        43\n","          11       0.71      0.67      0.69        45\n","          12       0.89      0.89      0.89        44\n","          13       0.67      0.52      0.59        46\n","          14       0.72      0.62      0.67        37\n","          15       0.79      0.85      0.81        39\n","          16       0.86      0.71      0.77        51\n","          17       0.70      0.66      0.68        53\n","          18       0.97      0.87      0.92        38\n","          19       0.71      0.84      0.77        38\n","          20       0.96      0.98      0.97        48\n","          21       0.72      0.62      0.67        34\n","          22       0.73      0.71      0.72        51\n","          23       0.83      0.74      0.78        39\n","          24       0.55      0.47      0.51        38\n","          25       0.84      0.82      0.83        38\n","          26       0.79      0.92      0.85        37\n","          27       0.98      0.87      0.92        47\n","          28       0.82      0.87      0.84        31\n","          29       0.70      0.77      0.73        43\n","          30       0.88      0.77      0.82        39\n","          31       0.76      0.77      0.76        44\n","          32       0.87      0.71      0.78        48\n","          33       0.69      0.69      0.69        39\n","          34       0.57      0.72      0.63        36\n","          35       0.79      0.72      0.75        32\n","          36       0.88      0.86      0.87        42\n","          37       0.66      0.50      0.57        42\n","          38       0.71      0.69      0.70        49\n","          39       0.79      0.72      0.76        43\n","          40       0.78      0.80      0.79        45\n","          41       0.86      0.83      0.84        46\n","          42       0.62      0.56      0.59        43\n","          43       0.86      0.90      0.88        49\n","          44       0.95      0.98      0.96        42\n","          45       0.71      0.76      0.73        45\n","          46       0.96      0.77      0.86        31\n","          47       0.72      0.65      0.68        48\n","          48       0.85      0.75      0.80        44\n","          49       0.81      0.76      0.79        34\n","          50       0.76      0.88      0.81        32\n","          51       0.71      0.56      0.63        48\n","          52       0.80      0.77      0.79        57\n","          53       0.68      0.63      0.66        41\n","          54       0.86      0.86      0.86        36\n","          55       0.58      0.59      0.58        44\n","          56       0.97      0.90      0.94        41\n","          57       0.80      0.88      0.84        32\n","          58       0.93      0.93      0.93        42\n","          59       0.94      0.89      0.91        36\n","          60       0.76      0.91      0.83        35\n","          61       0.79      0.73      0.76        37\n","          62       0.82      0.72      0.77        43\n","          63       0.66      0.53      0.59        43\n","          64       0.86      0.69      0.76        35\n","          65       0.72      0.74      0.73        39\n","          66       0.68      0.80      0.74        35\n","          67       0.84      0.88      0.86        42\n","          68       0.69      0.62      0.66        40\n","          69       0.79      0.64      0.71        42\n","          70       0.95      1.00      0.98        41\n","          71       0.71      0.86      0.78        29\n","          72       0.98      0.84      0.90        56\n","          73       0.90      0.86      0.88        43\n","          74       0.58      0.66      0.62        32\n","          75       0.93      0.97      0.95        40\n","          76       1.00      0.86      0.93        37\n","          77       0.62      0.58      0.60        31\n","          78       0.56      0.61      0.58        33\n","          79       0.69      0.64      0.67        53\n","          80       0.85      0.97      0.91        40\n","          81       0.72      0.74      0.73        39\n","          82       0.75      0.53      0.62        40\n","          83       0.87      0.85      0.86        39\n","          84       0.64      0.69      0.67        36\n","          85       0.93      0.91      0.92        47\n","          86       0.90      1.00      0.95        35\n","          87       0.86      0.84      0.85        37\n","          88       0.67      0.74      0.70        27\n","          89       0.59      0.50      0.54        40\n","          90       0.76      0.80      0.78        51\n","          91       0.75      0.60      0.67        40\n","          92       0.53      0.66      0.58        29\n","          93       0.88      0.98      0.92        50\n","          94       0.54      0.71      0.62        35\n","\n","    accuracy                           0.75      4400\n","   macro avg       0.78      0.76      0.77      4400\n","weighted avg       0.76      0.75      0.75      4400\n","\n","\n","Confusion Matrix:\n"," [[406   2   7 ...   5   3   5]\n"," [  2  19   0 ...   1   0   1]\n"," [  7   0  27 ...   0   0   0]\n"," ...\n"," [  4   0   0 ...  19   0   1]\n"," [  0   0   0 ...   0  49   0]\n"," [  1   1   0 ...   0   0  25]]\n"]}],"source":["from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n","\n","# 특징(X)와 타겟(y) 분리\n","X = data.drop(columns=['Label'])\n","y = data['Label']\n","\n","# 데이터를 훈련 세트와 테스트 세트로 분할\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# 랜덤 포레스트 모델 초기화\n","model = RandomForestClassifier(random_state=42)\n","\n","# GridSearchCV로 튜닝할 하이퍼파라미터 설정\n","param_grid = {\n","    'n_estimators': [100, 200, 300],\n","    'max_depth': [None, 10, 20, 30],\n","    'min_samples_split': [2, 5, 10],\n","    'min_samples_leaf': [1, 2, 4],\n","    'bootstrap': [True, False]\n","}\n","\n","# GridSearchCV 설정\n","grid_search = GridSearchCV(\n","    estimator=model,\n","    param_grid=param_grid,\n","    scoring='f1_weighted',\n","    cv=3,\n","    verbose=2,\n","    n_jobs=-1\n",")\n","\n","# GridSearchCV 수행\n","grid_search.fit(X_train, y_train)\n","\n","# 최적 하이퍼파라미터 및 최적 점수 출력\n","print(\"Best Parameters:\", grid_search.best_params_)\n","print(\"Best F1 Score (weighted):\", grid_search.best_score_)\n","\n","# 최적 모델로 테스트 세트 평가\n","best_model = grid_search.best_estimator_\n","y_pred = best_model.predict(X_test)\n","\n","accuracy = accuracy_score(y_test, y_pred)\n","f1 = f1_score(y_test, y_pred, average='weighted')\n","classification_rep = classification_report(y_test, y_pred)\n","conf_matrix = confusion_matrix(y_test, y_pred)\n","\n","print(f\"Accuracy: {accuracy}\")\n","print(f\"F1 Score (weighted): {f1}\")\n","print(\"\\nClassification Report:\\n\", classification_rep)\n","print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}