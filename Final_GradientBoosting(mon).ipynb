{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "aHIamnFN8Xhc"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gOO0YUlz4YHN"
      },
      "outputs": [],
      "source": [
        "mon=pd.read_csv('mon.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradient Boosting"
      ],
      "metadata": {
        "id": "IWRe8MnM8lUC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mR5hIw1l4YHN",
        "outputId": "a7cc3599-3a6b-49c9-f52f-e3bdeed4c19c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6692105263157895\n",
            "F1 Score (weighted): 0.6696687733440732\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.50      0.56        42\n",
            "           1       0.76      0.60      0.67        42\n",
            "           2       0.87      0.77      0.82        35\n",
            "           3       0.75      0.72      0.74        29\n",
            "           4       0.67      0.77      0.71        39\n",
            "           5       0.79      0.69      0.74        45\n",
            "           6       0.77      0.84      0.80        44\n",
            "           7       0.71      0.67      0.69        36\n",
            "           8       0.62      0.53      0.57        34\n",
            "           9       0.59      0.71      0.65        31\n",
            "          10       0.64      0.62      0.63        47\n",
            "          11       0.62      0.71      0.67        35\n",
            "          12       0.86      0.71      0.78        42\n",
            "          13       0.52      0.35      0.42        40\n",
            "          14       0.69      0.56      0.62        36\n",
            "          15       0.63      0.69      0.66        35\n",
            "          16       0.77      0.70      0.73        43\n",
            "          17       0.62      0.70      0.66        47\n",
            "          18       0.87      0.73      0.79        37\n",
            "          19       0.89      0.68      0.77        37\n",
            "          20       0.93      0.84      0.88        44\n",
            "          21       0.63      0.46      0.54        41\n",
            "          22       0.55      0.45      0.49        40\n",
            "          23       0.68      0.77      0.72        35\n",
            "          24       0.28      0.28      0.28        46\n",
            "          25       0.68      0.58      0.63        36\n",
            "          26       0.66      0.84      0.74        37\n",
            "          27       0.66      0.64      0.65        45\n",
            "          28       0.74      0.64      0.69        36\n",
            "          29       0.63      0.72      0.67        47\n",
            "          30       0.82      0.70      0.75        46\n",
            "          31       0.56      0.78      0.65        37\n",
            "          32       0.50      0.47      0.49        38\n",
            "          33       0.70      0.81      0.75        37\n",
            "          34       0.51      0.46      0.49        41\n",
            "          35       0.83      0.76      0.79        38\n",
            "          36       0.82      0.89      0.85        35\n",
            "          37       0.50      0.36      0.42        53\n",
            "          38       0.53      0.58      0.56        53\n",
            "          39       0.74      0.57      0.64        46\n",
            "          40       0.78      0.76      0.77        51\n",
            "          41       0.83      0.79      0.81        43\n",
            "          42       0.47      0.62      0.53        39\n",
            "          43       0.81      0.85      0.83        41\n",
            "          44       0.93      0.98      0.96        44\n",
            "          45       0.45      0.57      0.51        35\n",
            "          46       0.66      0.71      0.68        35\n",
            "          47       0.69      0.56      0.62        39\n",
            "          48       0.67      0.76      0.71        37\n",
            "          49       0.70      0.60      0.65        43\n",
            "          50       0.66      0.72      0.69        32\n",
            "          51       0.49      0.58      0.53        38\n",
            "          52       0.73      0.76      0.74        49\n",
            "          53       0.47      0.71      0.56        31\n",
            "          54       0.81      0.74      0.78        47\n",
            "          55       0.56      0.56      0.56        41\n",
            "          56       0.86      0.89      0.88        47\n",
            "          57       0.67      0.61      0.64        36\n",
            "          58       0.81      0.83      0.82        35\n",
            "          59       0.82      0.85      0.84        39\n",
            "          60       0.65      0.75      0.70        40\n",
            "          61       0.57      0.48      0.52        56\n",
            "          62       0.70      0.54      0.61        57\n",
            "          63       0.46      0.67      0.55        27\n",
            "          64       0.63      0.67      0.65        39\n",
            "          65       0.45      0.60      0.51        35\n",
            "          66       0.85      0.76      0.80        46\n",
            "          67       0.71      0.73      0.72        37\n",
            "          68       0.74      0.42      0.53        48\n",
            "          69       0.73      0.70      0.71        43\n",
            "          70       0.97      0.85      0.91        34\n",
            "          71       0.50      0.75      0.60        36\n",
            "          72       0.69      0.64      0.67        39\n",
            "          73       0.88      0.88      0.88        41\n",
            "          74       0.64      0.57      0.60        53\n",
            "          75       0.90      0.95      0.92        37\n",
            "          76       0.95      0.86      0.90        44\n",
            "          77       0.37      0.50      0.42        30\n",
            "          78       0.36      0.72      0.48        36\n",
            "          79       0.62      0.60      0.61        30\n",
            "          80       0.78      0.78      0.78        40\n",
            "          81       0.63      0.64      0.64        45\n",
            "          82       0.56      0.49      0.52        45\n",
            "          83       0.51      0.71      0.59        31\n",
            "          84       0.72      0.65      0.68        40\n",
            "          85       0.83      0.77      0.80        44\n",
            "          86       0.76      0.92      0.83        37\n",
            "          87       0.69      0.69      0.69        35\n",
            "          88       0.66      0.62      0.64        37\n",
            "          89       0.55      0.42      0.48        38\n",
            "          90       0.57      0.69      0.62        36\n",
            "          91       0.67      0.67      0.67        39\n",
            "          92       0.54      0.54      0.54        35\n",
            "          93       0.89      0.87      0.88        39\n",
            "          94       0.51      0.50      0.51        42\n",
            "\n",
            "    accuracy                           0.67      3800\n",
            "   macro avg       0.68      0.67      0.67      3800\n",
            "weighted avg       0.68      0.67      0.67      3800\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            " [[21  0  0 ...  0  0  1]\n",
            " [ 0 25  3 ...  0  0  0]\n",
            " [ 0  0 27 ...  2  0  0]\n",
            " ...\n",
            " [ 0  0  0 ... 19  0  0]\n",
            " [ 0  0  0 ...  0 34  0]\n",
            " [ 0  0  0 ...  2  0 21]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
        "\n",
        "# 특징(X)와 타겟(y) 분리\n",
        "X = mon.drop(columns=['Label'])\n",
        "y = mon['Label']\n",
        "\n",
        "# 데이터를 훈련 세트와 테스트 세트로 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Gradient Boosting 모델 초기화 및 학습\n",
        "model = GradientBoostingClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 테스트 세트 예측\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# 성능 평가\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')  # 가중 평균 F1 점수 계산\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"F1 Score (weighted): {f1}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_rep)\n",
        "print(\"\\nConfusion Matrix:\\n\", conf_matrix)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}