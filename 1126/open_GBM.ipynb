{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dxw902Dx7w6m",
        "outputId": "2be1d0cb-c41a-4a39-d350-8f177d25ecfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.10/dist-packages (4.5.0)\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.13.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.8.0)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.2.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (9.0.0)\n",
            "Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.7\n"
          ]
        }
      ],
      "source": [
        "!pip install lightgbm catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "UTzViB9NxLCm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from catboost import CatBoostClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "aI-C6eG35c7i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aed7975c-ce43-4ded-827b-0c5543bc8fb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label Distribution:\n",
            "Label\n",
            "1    19000\n",
            "0     3000\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "data = pd.read_csv(\"/content/monunmon.csv\")  # CSV 파일 경로\n",
        "\n",
        "# 레이블 이진 분류를 위해 변환 (0~94 -> 1, -1 -> 0)\n",
        "data['Label'] = data['Label'].apply(lambda x: 1 if x >= 0 else 0)\n",
        "\n",
        "# 변환 결과 확인\n",
        "print(\"Label Distribution:\")\n",
        "print(data['Label'].value_counts())\n",
        "\n",
        "# 특성과 레이블 분리\n",
        "X = data.drop(columns=['Label'])  # 피처 데이터\n",
        "y = data['Label']  # 레이블 데이터\n",
        "\n",
        "# Train, Validation, Test 데이터 나누기\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#오리지널 데이터 사용"
      ],
      "metadata": {
        "id": "Lh2JOUw4uU81"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Gradient Boosting Classifier"
      ],
      "metadata": {
        "id": "dXhOASUBuc65"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yAANcl85i15",
        "outputId": "2bbf5912-74ff-4213-85c4-7767db01a6ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.89\n",
            "Validation F1 Score: 0.94\n",
            "\n",
            "Test Accuracy: 0.90\n",
            "Test F1 Score: 0.94\n",
            "\n",
            "Classification Report on Test Data:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.28      0.42       450\n",
            "           1       0.90      0.99      0.94      2850\n",
            "\n",
            "    accuracy                           0.90      3300\n",
            "   macro avg       0.88      0.64      0.68      3300\n",
            "weighted avg       0.89      0.90      0.87      3300\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Gradient Boosting Classifier\n",
        "model = GradientBoostingClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred_gbc = model.predict(X_test)\n",
        "\n",
        "# 검증 데이터 평가\n",
        "y_val_pred = model.predict(X_val)\n",
        "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
        "val_f1 = f1_score(y_val, y_val_pred)\n",
        "\n",
        "print(f\"Validation Accuracy: {val_accuracy:.2f}\")\n",
        "print(f\"Validation F1 Score: {val_f1:.2f}\")\n",
        "\n",
        "# 테스트 데이터 평가\n",
        "y_test_pred = model.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "test_f1 = f1_score(y_test, y_test_pred)\n",
        "\n",
        "print(f\"\\nTest Accuracy: {test_accuracy:.2f}\")\n",
        "print(f\"Test F1 Score: {test_f1:.2f}\")\n",
        "\n",
        "# 분류 보고서 출력\n",
        "print(\"\\nClassification Report on Test Data:\")\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#클래스별 Accuracy 계산\n",
        "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
        "class_0_accuracy = conf_matrix[0, 0] / conf_matrix[0].sum()  # TP / (TP + FN) for class 0\n",
        "class_1_accuracy = conf_matrix[1, 1] / conf_matrix[1].sum()  # TP / (TP + FN) for class 1\n",
        "\n",
        "# 클래스별 Accuracy 출력\n",
        "print(f\"\\nTest Class 0 Accuracy: {class_0_accuracy:.2f}\")\n",
        "print(f\"Test Class 1 Accuracy: {class_1_accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13FCblVu-E4O",
        "outputId": "358d671b-0ef5-4545-f3e9-8d8b194df272"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Class 0 Accuracy: 0.28\n",
            "Test Class 1 Accuracy: 0.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##XGBoost"
      ],
      "metadata": {
        "id": "cgtmmEDk-YYh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ga3lXBxR6J_8",
        "outputId": "0819ffd8-0639-4cad-8aeb-377b984e131a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [05:42:11] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.91\n",
            "Validation F1 Score: 0.95\n",
            "Test Accuracy: 0.91\n",
            "Test F1 Score: 0.95\n",
            "\n",
            "Classification Report on Test Data:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.44      0.57       450\n",
            "           1       0.92      0.98      0.95      2850\n",
            "\n",
            "    accuracy                           0.91      3300\n",
            "   macro avg       0.87      0.71      0.76      3300\n",
            "weighted avg       0.90      0.91      0.90      3300\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
        "\n",
        "# XGBoost Classifier 학습\n",
        "xgb = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
        "xgb.fit(X_train, y_train)\n",
        "\n",
        "# 검증 데이터 평가\n",
        "y_val_pred = xgb.predict(X_val)\n",
        "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
        "val_f1 = f1_score(y_val, y_val_pred)\n",
        "\n",
        "print(f\"Validation Accuracy: {val_accuracy:.2f}\")\n",
        "print(f\"Validation F1 Score: {val_f1:.2f}\")\n",
        "\n",
        "# 테스트 데이터 평가\n",
        "y_test_pred = xgb.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "test_f1 = f1_score(y_test, y_test_pred)\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
        "print(f\"Test F1 Score: {test_f1:.2f}\")\n",
        "\n",
        "# 분류 보고서 출력\n",
        "print(\"\\nClassification Report on Test Data:\")\n",
        "print(classification_report(y_test, y_test_pred))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#클래스별 Accuracy 계산\n",
        "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
        "class_0_accuracy = conf_matrix[0, 0] / conf_matrix[0].sum()  # TP / (TP + FN) for class 0\n",
        "class_1_accuracy = conf_matrix[1, 1] / conf_matrix[1].sum()  # TP / (TP + FN) for class 1\n",
        "\n",
        "# 클래스별 Accuracy 출력\n",
        "print(f\"\\nTest Class 0 Accuracy: {class_0_accuracy:.2f}\")\n",
        "print(f\"Test Class 1 Accuracy: {class_1_accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4T86oMm-se8",
        "outputId": "08970195-e374-44b8-aff3-b39313581e96"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Class 0 Accuracy: 0.44\n",
            "Test Class 1 Accuracy: 0.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##LightGBM"
      ],
      "metadata": {
        "id": "MBlzbwV-_h34"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goVnVwBD7NCo",
        "outputId": "96582ef4-894f-428b-894c-9c8c2a001413"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Number of positive: 13300, number of negative: 2100\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001965 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3345\n",
            "[LightGBM] [Info] Number of data points in the train set: 15400, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.863636 -> initscore=1.845827\n",
            "[LightGBM] [Info] Start training from score 1.845827\n",
            "Validation Accuracy: 0.91\n",
            "Validation F1 Score: 0.95\n",
            "Test Accuracy: 0.91\n",
            "Test F1 Score: 0.95\n",
            "\n",
            "Classification Report on Test Data:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.38      0.52       450\n",
            "           1       0.91      0.99      0.95      2850\n",
            "\n",
            "    accuracy                           0.91      3300\n",
            "   macro avg       0.88      0.68      0.73      3300\n",
            "weighted avg       0.90      0.91      0.89      3300\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# LightGBM Classifier\n",
        "lgbm = LGBMClassifier(random_state=42)\n",
        "lgbm.fit(X_train, y_train)\n",
        "\n",
        "# 검증 데이터 평가\n",
        "y_val_pred = lgbm.predict(X_val)\n",
        "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
        "val_f1 = f1_score(y_val, y_val_pred)\n",
        "\n",
        "print(f\"Validation Accuracy: {val_accuracy:.2f}\")\n",
        "print(f\"Validation F1 Score: {val_f1:.2f}\")\n",
        "\n",
        "# 테스트 데이터 평가\n",
        "y_test_pred = lgbm.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "test_f1 = f1_score(y_test, y_test_pred)\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
        "print(f\"Test F1 Score: {test_f1:.2f}\")\n",
        "\n",
        "# 분류 보고서 출력\n",
        "print(\"\\nClassification Report on Test Data:\")\n",
        "print(classification_report(y_test, y_test_pred))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#클래스별 Accuracy 계산\n",
        "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
        "class_0_accuracy = conf_matrix[0, 0] / conf_matrix[0].sum()  # TP / (TP + FN) for class 0\n",
        "class_1_accuracy = conf_matrix[1, 1] / conf_matrix[1].sum()  # TP / (TP + FN) for class 1\n",
        "\n",
        "# 클래스별 Accuracy 출력\n",
        "print(f\"\\nTest Class 0 Accuracy: {class_0_accuracy:.2f}\")\n",
        "print(f\"Test Class 1 Accuracy: {class_1_accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KquwwDB-_8k1",
        "outputId": "5495466d-3feb-4b7b-8ce4-f25f3c7ef44f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Class 0 Accuracy: 0.38\n",
            "Test Class 1 Accuracy: 0.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##catBoost"
      ],
      "metadata": {
        "id": "0TdtpDG5AAKK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RJfku-z7fSj",
        "outputId": "27690968-51f9-4360-b8b1-46b4f6a75676"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.91\n",
            "Validation F1 Score: 0.95\n",
            "Test Accuracy: 0.90\n",
            "Test F1 Score: 0.95\n",
            "\n",
            "Classification Report on Test Data:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.38      0.52       450\n",
            "           1       0.91      0.99      0.95      2850\n",
            "\n",
            "    accuracy                           0.90      3300\n",
            "   macro avg       0.87      0.68      0.73      3300\n",
            "weighted avg       0.90      0.90      0.89      3300\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# CatBoost Classifier\n",
        "catboost = CatBoostClassifier(random_state=42, verbose=0)  # verbose=0으로 출력 제한\n",
        "catboost.fit(X_train, y_train)\n",
        "\n",
        "# 검증 데이터 평가\n",
        "y_val_pred = catboost.predict(X_val)\n",
        "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
        "val_f1 = f1_score(y_val, y_val_pred)\n",
        "\n",
        "print(f\"Validation Accuracy: {val_accuracy:.2f}\")\n",
        "print(f\"Validation F1 Score: {val_f1:.2f}\")\n",
        "\n",
        "# 테스트 데이터 평가\n",
        "y_test_pred = catboost.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "test_f1 = f1_score(y_test, y_test_pred)\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
        "print(f\"Test F1 Score: {test_f1:.2f}\")\n",
        "\n",
        "# 분류 보고서 출력\n",
        "print(\"\\nClassification Report on Test Data:\")\n",
        "print(classification_report(y_test, y_test_pred))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#클래스별 Accuracy 계산\n",
        "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
        "class_0_accuracy = conf_matrix[0, 0] / conf_matrix[0].sum()  # TP / (TP + FN) for class 0\n",
        "class_1_accuracy = conf_matrix[1, 1] / conf_matrix[1].sum()  # TP / (TP + FN) for class 1\n",
        "\n",
        "# 클래스별 Accuracy 출력\n",
        "print(f\"\\nTest Class 0 Accuracy: {class_0_accuracy:.2f}\")\n",
        "print(f\"Test Class 1 Accuracy: {class_1_accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ol72vfWAO0F",
        "outputId": "93a0a4be-ea25-40e1-97d0-b83f0e35463f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Class 0 Accuracy: 0.38\n",
            "Test Class 1 Accuracy: 0.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##adaBoost"
      ],
      "metadata": {
        "id": "F03RdjuPAXOX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zbc7tH7753sC",
        "outputId": "f5a5f0ef-965f-4b9b-af98-1032a0ddecf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.89\n",
            "Validation F1 Score: 0.94\n",
            "Test Accuracy: 0.89\n",
            "Test F1 Score: 0.94\n",
            "\n",
            "Classification Report on Test Data:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.25      0.37       450\n",
            "           1       0.89      0.99      0.94      2850\n",
            "\n",
            "    accuracy                           0.89      3300\n",
            "   macro avg       0.82      0.62      0.65      3300\n",
            "weighted avg       0.87      0.89      0.86      3300\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# AdaBoost Classifier 사용\n",
        "abc = AdaBoostClassifier(random_state=42)\n",
        "abc.fit(X_train, y_train)\n",
        "\n",
        "# 검증 데이터 평가\n",
        "y_val_pred = abc.predict(X_val)\n",
        "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
        "val_f1 = f1_score(y_val, y_val_pred)\n",
        "\n",
        "print(f\"Validation Accuracy: {val_accuracy:.2f}\")\n",
        "print(f\"Validation F1 Score: {val_f1:.2f}\")\n",
        "\n",
        "# 테스트 데이터 평가\n",
        "y_test_pred = abc.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "test_f1 = f1_score(y_test, y_test_pred)\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
        "print(f\"Test F1 Score: {test_f1:.2f}\")\n",
        "\n",
        "# 분류 보고서 출력\n",
        "print(\"\\nClassification Report on Test Data:\")\n",
        "print(classification_report(y_test, y_test_pred))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#클래스별 Accuracy 계산\n",
        "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
        "class_0_accuracy = conf_matrix[0, 0] / conf_matrix[0].sum()  # TP / (TP + FN) for class 0\n",
        "class_1_accuracy = conf_matrix[1, 1] / conf_matrix[1].sum()  # TP / (TP + FN) for class 1\n",
        "\n",
        "# 클래스별 Accuracy 출력\n",
        "print(f\"\\nTest Class 0 Accuracy: {class_0_accuracy:.2f}\")\n",
        "print(f\"Test Class 1 Accuracy: {class_1_accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxuiffUzAkHj",
        "outputId": "c1fc6b57-474c-48de-d6dd-c0dc2d760468"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Class 0 Accuracy: 0.25\n",
            "Test Class 1 Accuracy: 0.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#0 oversampling 한 데이터"
      ],
      "metadata": {
        "id": "RM9bocNKA4lv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##데이터 생성"
      ],
      "metadata": {
        "id": "ccpmpP8HBZge"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDbLdc0N-frl",
        "outputId": "57febd70-9ce8-456d-b5ae-81c53665976a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.12.4)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.5.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (3.5.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install imbalanced-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE"
      ],
      "metadata": {
        "id": "NAqTiTLnBGgk"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/monunmon.csv\")  # CSV 파일 경로\n",
        "\n",
        "# 레이블 이진 분류를 위해 변환 (0~94 -> 1, -1 -> 0)\n",
        "data['Label'] = data['Label'].apply(lambda x: 1 if x >= 0 else 0)\n",
        "\n",
        "# 변환 결과 확인\n",
        "print(\"Label Distribution:\")\n",
        "print(data['Label'].value_counts())\n",
        "\n",
        "# 특성과 레이블 분리\n",
        "X = data.drop(columns=['Label'])  # 피처 데이터\n",
        "y = data['Label']  # 레이블 데이터\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8LDLILkBNVC",
        "outputId": "a6f8a7fc-0b9b-4cfb-c85c-8954378d54ba"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label Distribution:\n",
            "Label\n",
            "1    19000\n",
            "0     3000\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5s6Df9st-o3w",
        "outputId": "75c94de3-6fd1-4c92-92ed-a5b798adbdfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataset size: 22000\n",
            "Resampled dataset size: 38000\n"
          ]
        }
      ],
      "source": [
        "# SMOTE 적용\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "\n",
        "print(\"Original dataset size:\", X.shape[0])\n",
        "print(\"Resampled dataset size:\", X_resampled.shape[0])\n",
        "\n",
        "# Train, Validation, Test 데이터 나누기\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=42, stratify=y_resampled)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Gradient Boosting Classifier"
      ],
      "metadata": {
        "id": "eoodsjqyBpjs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec9022d1-d585-41c1-bf6f-61fecc2056d1",
        "id": "tZxdtM4yBpjt"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.89\n",
            "Validation F1 Score: 0.90\n",
            "\n",
            "Test Accuracy: 0.90\n",
            "Test F1 Score: 0.90\n",
            "\n",
            "Classification Report on Test Data:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.84      0.89      2850\n",
            "           1       0.86      0.95      0.90      2850\n",
            "\n",
            "    accuracy                           0.90      5700\n",
            "   macro avg       0.90      0.90      0.90      5700\n",
            "weighted avg       0.90      0.90      0.90      5700\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Gradient Boosting Classifier\n",
        "model = GradientBoostingClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred_gbc = model.predict(X_test)\n",
        "\n",
        "# 검증 데이터 평가\n",
        "y_val_pred = model.predict(X_val)\n",
        "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
        "val_f1 = f1_score(y_val, y_val_pred)\n",
        "\n",
        "print(f\"Validation Accuracy: {val_accuracy:.2f}\")\n",
        "print(f\"Validation F1 Score: {val_f1:.2f}\")\n",
        "\n",
        "# 테스트 데이터 평가\n",
        "y_test_pred = model.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "test_f1 = f1_score(y_test, y_test_pred)\n",
        "\n",
        "print(f\"\\nTest Accuracy: {test_accuracy:.2f}\")\n",
        "print(f\"Test F1 Score: {test_f1:.2f}\")\n",
        "\n",
        "# 분류 보고서 출력\n",
        "print(\"\\nClassification Report on Test Data:\")\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#클래스별 Accuracy 계산\n",
        "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
        "class_0_accuracy = conf_matrix[0, 0] / conf_matrix[0].sum()  # TP / (TP + FN) for class 0\n",
        "class_1_accuracy = conf_matrix[1, 1] / conf_matrix[1].sum()  # TP / (TP + FN) for class 1\n",
        "\n",
        "# 클래스별 Accuracy 출력\n",
        "print(f\"\\nTest Class 0 Accuracy: {class_0_accuracy:.2f}\")\n",
        "print(f\"Test Class 1 Accuracy: {class_1_accuracy:.2f}\")"
      ],
      "metadata": {
        "outputId": "2084335d-7d61-4377-bede-45d1b3400dd8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuDns3GLBpju"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Class 0 Accuracy: 0.84\n",
            "Test Class 1 Accuracy: 0.95\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##XGBoost"
      ],
      "metadata": {
        "id": "4uNyBQP4DLe_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c30205a-5558-44af-bf5d-77f8eb26668b",
        "id": "SdICvR99DLfA"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [05:59:43] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.93\n",
            "Validation F1 Score: 0.93\n",
            "Test Accuracy: 0.93\n",
            "Test F1 Score: 0.93\n",
            "\n",
            "Classification Report on Test Data:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.90      0.93      2850\n",
            "           1       0.91      0.96      0.93      2850\n",
            "\n",
            "    accuracy                           0.93      5700\n",
            "   macro avg       0.93      0.93      0.93      5700\n",
            "weighted avg       0.93      0.93      0.93      5700\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
        "\n",
        "# XGBoost Classifier 학습\n",
        "xgb = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
        "xgb.fit(X_train, y_train)\n",
        "\n",
        "# 검증 데이터 평가\n",
        "y_val_pred = xgb.predict(X_val)\n",
        "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
        "val_f1 = f1_score(y_val, y_val_pred)\n",
        "\n",
        "print(f\"Validation Accuracy: {val_accuracy:.2f}\")\n",
        "print(f\"Validation F1 Score: {val_f1:.2f}\")\n",
        "\n",
        "# 테스트 데이터 평가\n",
        "y_test_pred = xgb.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "test_f1 = f1_score(y_test, y_test_pred)\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
        "print(f\"Test F1 Score: {test_f1:.2f}\")\n",
        "\n",
        "# 분류 보고서 출력\n",
        "print(\"\\nClassification Report on Test Data:\")\n",
        "print(classification_report(y_test, y_test_pred))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#클래스별 Accuracy 계산\n",
        "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
        "class_0_accuracy = conf_matrix[0, 0] / conf_matrix[0].sum()  # TP / (TP + FN) for class 0\n",
        "class_1_accuracy = conf_matrix[1, 1] / conf_matrix[1].sum()  # TP / (TP + FN) for class 1\n",
        "\n",
        "# 클래스별 Accuracy 출력\n",
        "print(f\"\\nTest Class 0 Accuracy: {class_0_accuracy:.2f}\")\n",
        "print(f\"Test Class 1 Accuracy: {class_1_accuracy:.2f}\")"
      ],
      "metadata": {
        "outputId": "8e5c11d6-9611-4f76-f080-87522bbc3f00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCnXgsiUDLfA"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Class 0 Accuracy: 0.90\n",
            "Test Class 1 Accuracy: 0.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##LightGBM"
      ],
      "metadata": {
        "id": "gvFbWP2xDLfB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a4a2b2a-274c-4d0f-e3bd-40642d3a80ea",
        "id": "0jImIhHeDLfC"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Number of positive: 13300, number of negative: 13300\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004385 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3825\n",
            "[LightGBM] [Info] Number of data points in the train set: 26600, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "Validation Accuracy: 0.92\n",
            "Validation F1 Score: 0.92\n",
            "Test Accuracy: 0.92\n",
            "Test F1 Score: 0.92\n",
            "\n",
            "Classification Report on Test Data:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.88      0.92      2850\n",
            "           1       0.89      0.96      0.92      2850\n",
            "\n",
            "    accuracy                           0.92      5700\n",
            "   macro avg       0.92      0.92      0.92      5700\n",
            "weighted avg       0.92      0.92      0.92      5700\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# LightGBM Classifier\n",
        "lgbm = LGBMClassifier(random_state=42)\n",
        "lgbm.fit(X_train, y_train)\n",
        "\n",
        "# 검증 데이터 평가\n",
        "y_val_pred = lgbm.predict(X_val)\n",
        "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
        "val_f1 = f1_score(y_val, y_val_pred)\n",
        "\n",
        "print(f\"Validation Accuracy: {val_accuracy:.2f}\")\n",
        "print(f\"Validation F1 Score: {val_f1:.2f}\")\n",
        "\n",
        "# 테스트 데이터 평가\n",
        "y_test_pred = lgbm.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "test_f1 = f1_score(y_test, y_test_pred)\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
        "print(f\"Test F1 Score: {test_f1:.2f}\")\n",
        "\n",
        "# 분류 보고서 출력\n",
        "print(\"\\nClassification Report on Test Data:\")\n",
        "print(classification_report(y_test, y_test_pred))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#클래스별 Accuracy 계산\n",
        "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
        "class_0_accuracy = conf_matrix[0, 0] / conf_matrix[0].sum()  # TP / (TP + FN) for class 0\n",
        "class_1_accuracy = conf_matrix[1, 1] / conf_matrix[1].sum()  # TP / (TP + FN) for class 1\n",
        "\n",
        "# 클래스별 Accuracy 출력\n",
        "print(f\"\\nTest Class 0 Accuracy: {class_0_accuracy:.2f}\")\n",
        "print(f\"Test Class 1 Accuracy: {class_1_accuracy:.2f}\")"
      ],
      "metadata": {
        "outputId": "a7b46f1c-4db8-48a7-8834-79dcab625882",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XcN1YjnDLfC"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Class 0 Accuracy: 0.88\n",
            "Test Class 1 Accuracy: 0.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##catBoost"
      ],
      "metadata": {
        "id": "CfaIQidHDLfC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a60b5f1-3728-429e-8819-14c3a8d2c6ab",
        "id": "TxcFx0p_DLfC"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.93\n",
            "Validation F1 Score: 0.93\n",
            "Test Accuracy: 0.93\n",
            "Test F1 Score: 0.93\n",
            "\n",
            "Classification Report on Test Data:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.89      0.93      2850\n",
            "           1       0.90      0.97      0.93      2850\n",
            "\n",
            "    accuracy                           0.93      5700\n",
            "   macro avg       0.93      0.93      0.93      5700\n",
            "weighted avg       0.93      0.93      0.93      5700\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# CatBoost Classifier\n",
        "catboost = CatBoostClassifier(random_state=42, verbose=0)  # verbose=0으로 출력 제한\n",
        "catboost.fit(X_train, y_train)\n",
        "\n",
        "# 검증 데이터 평가\n",
        "y_val_pred = catboost.predict(X_val)\n",
        "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
        "val_f1 = f1_score(y_val, y_val_pred)\n",
        "\n",
        "print(f\"Validation Accuracy: {val_accuracy:.2f}\")\n",
        "print(f\"Validation F1 Score: {val_f1:.2f}\")\n",
        "\n",
        "# 테스트 데이터 평가\n",
        "y_test_pred = catboost.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "test_f1 = f1_score(y_test, y_test_pred)\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
        "print(f\"Test F1 Score: {test_f1:.2f}\")\n",
        "\n",
        "# 분류 보고서 출력\n",
        "print(\"\\nClassification Report on Test Data:\")\n",
        "print(classification_report(y_test, y_test_pred))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#클래스별 Accuracy 계산\n",
        "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
        "class_0_accuracy = conf_matrix[0, 0] / conf_matrix[0].sum()  # TP / (TP + FN) for class 0\n",
        "class_1_accuracy = conf_matrix[1, 1] / conf_matrix[1].sum()  # TP / (TP + FN) for class 1\n",
        "\n",
        "# 클래스별 Accuracy 출력\n",
        "print(f\"\\nTest Class 0 Accuracy: {class_0_accuracy:.2f}\")\n",
        "print(f\"Test Class 1 Accuracy: {class_1_accuracy:.2f}\")"
      ],
      "metadata": {
        "outputId": "9e15868a-db41-425e-d256-39ab0e07ba66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfoSuxM3DLfC"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Class 0 Accuracy: 0.89\n",
            "Test Class 1 Accuracy: 0.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##adaBoost"
      ],
      "metadata": {
        "id": "Xk66Dzs2DLfD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc9b5909-b04b-4168-dd4b-659b81a06e97",
        "id": "hPQD9YsJDLfD"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.86\n",
            "Validation F1 Score: 0.86\n",
            "Test Accuracy: 0.86\n",
            "Test F1 Score: 0.87\n",
            "\n",
            "Classification Report on Test Data:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.82      0.86      2850\n",
            "           1       0.83      0.90      0.87      2850\n",
            "\n",
            "    accuracy                           0.86      5700\n",
            "   macro avg       0.86      0.86      0.86      5700\n",
            "weighted avg       0.86      0.86      0.86      5700\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# AdaBoost Classifier 사용\n",
        "abc = AdaBoostClassifier(random_state=42)\n",
        "abc.fit(X_train, y_train)\n",
        "\n",
        "# 검증 데이터 평가\n",
        "y_val_pred = abc.predict(X_val)\n",
        "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
        "val_f1 = f1_score(y_val, y_val_pred)\n",
        "\n",
        "print(f\"Validation Accuracy: {val_accuracy:.2f}\")\n",
        "print(f\"Validation F1 Score: {val_f1:.2f}\")\n",
        "\n",
        "# 테스트 데이터 평가\n",
        "y_test_pred = abc.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "test_f1 = f1_score(y_test, y_test_pred)\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
        "print(f\"Test F1 Score: {test_f1:.2f}\")\n",
        "\n",
        "# 분류 보고서 출력\n",
        "print(\"\\nClassification Report on Test Data:\")\n",
        "print(classification_report(y_test, y_test_pred))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#클래스별 Accuracy 계산\n",
        "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
        "class_0_accuracy = conf_matrix[0, 0] / conf_matrix[0].sum()  # TP / (TP + FN) for class 0\n",
        "class_1_accuracy = conf_matrix[1, 1] / conf_matrix[1].sum()  # TP / (TP + FN) for class 1\n",
        "\n",
        "# 클래스별 Accuracy 출력\n",
        "print(f\"\\nTest Class 0 Accuracy: {class_0_accuracy:.2f}\")\n",
        "print(f\"Test Class 1 Accuracy: {class_1_accuracy:.2f}\")"
      ],
      "metadata": {
        "outputId": "d0862dcb-c2a4-466f-996b-9a133ff131f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQFSdo3vDLfD"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Class 0 Accuracy: 0.82\n",
            "Test Class 1 Accuracy: 0.90\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSf-uP3TBOx7"
      },
      "source": [
        "**GBC와 AdaBoost:**\n",
        "\n",
        "SMOTE로 생성된 합성 데이터가 원본 데이터와 다소 다른 분포를 가질 경우, 모델 성능이 저하될 가능성이 높음.\n",
        "특히 AdaBoost는 잘못된 데이터에 민감함.\n",
        "\n",
        "\n",
        "**CatBoost, LightGBM, XGBoost:**\n",
        "\n",
        "이러한 알고리즘들은 데이터 노이즈와 불균형에 더 잘 대처하는 구조를 가짐."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiZTZa4x9dIV"
      },
      "source": [
        "#0에 weighted 가중치 부여한 데이터\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/monunmon.csv\")  # CSV 파일 경로\n",
        "\n",
        "# 레이블 이진 분류를 위해 변환 (0~94 -> 1, -1 -> 0)\n",
        "data['Label'] = data['Label'].apply(lambda x: 1 if x >= 0 else 0)\n",
        "\n",
        "# 변환 결과 확인\n",
        "print(\"Label Distribution:\")\n",
        "print(data['Label'].value_counts())\n",
        "\n",
        "# 특성과 레이블 분리\n",
        "X = data.drop(columns=['Label'])  # 피처 데이터\n",
        "y = data['Label']  # 레이블 데이터\n",
        "\n",
        "# Train, Validation, Test 데이터 나누기\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n"
      ],
      "metadata": {
        "outputId": "4bde5dd4-361c-4b02-bc56-061ec3629a46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lh5r9FThEPyE"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label Distribution:\n",
            "Label\n",
            "1    19000\n",
            "0     3000\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Gradient Boosting Classifier"
      ],
      "metadata": {
        "id": "piiRFBU5EPyE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "sample_weights = compute_sample_weight(class_weight='balanced', y=y_train)"
      ],
      "metadata": {
        "id": "9Ikw3NuPFSGg"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ebd8616-58a3-4fa0-f46c-1c25b046718f",
        "id": "_wRgMYWdEPyF"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.79\n",
            "Validation F1 Score: 0.87\n",
            "\n",
            "Test Accuracy: 0.79\n",
            "Test F1 Score: 0.86\n",
            "\n",
            "Classification Report on Test Data:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.36      0.72      0.48       450\n",
            "           1       0.95      0.80      0.86      2850\n",
            "\n",
            "    accuracy                           0.79      3300\n",
            "   macro avg       0.65      0.76      0.67      3300\n",
            "weighted avg       0.87      0.79      0.81      3300\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Gradient Boosting Classifier\n",
        "model = GradientBoostingClassifier(random_state=42)\n",
        "model.fit(X_train, y_train, sample_weight=sample_weights)\n",
        "y_pred_gbc = model.predict(X_test)\n",
        "\n",
        "# 검증 데이터 평가\n",
        "y_val_pred = model.predict(X_val)\n",
        "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
        "val_f1 = f1_score(y_val, y_val_pred)\n",
        "\n",
        "print(f\"Validation Accuracy: {val_accuracy:.2f}\")\n",
        "print(f\"Validation F1 Score: {val_f1:.2f}\")\n",
        "\n",
        "# 테스트 데이터 평가\n",
        "y_test_pred = model.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "test_f1 = f1_score(y_test, y_test_pred)\n",
        "\n",
        "print(f\"\\nTest Accuracy: {test_accuracy:.2f}\")\n",
        "print(f\"Test F1 Score: {test_f1:.2f}\")\n",
        "\n",
        "# 분류 보고서 출력\n",
        "print(\"\\nClassification Report on Test Data:\")\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#클래스별 Accuracy 계산\n",
        "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
        "class_0_accuracy = conf_matrix[0, 0] / conf_matrix[0].sum()  # TP / (TP + FN) for class 0\n",
        "class_1_accuracy = conf_matrix[1, 1] / conf_matrix[1].sum()  # TP / (TP + FN) for class 1\n",
        "\n",
        "# 클래스별 Accuracy 출력\n",
        "print(f\"\\nTest Class 0 Accuracy: {class_0_accuracy:.2f}\")\n",
        "print(f\"Test Class 1 Accuracy: {class_1_accuracy:.2f}\")"
      ],
      "metadata": {
        "outputId": "bfebd8ea-8a60-48cf-b629-e757148edeba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuo75L33EPyF"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Class 0 Accuracy: 0.72\n",
            "Test Class 1 Accuracy: 0.80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##XGBoost"
      ],
      "metadata": {
        "id": "yjka7XZyEPyF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "scale_pos_weight = Negative Sample 수 / Positive Sample 수"
      ],
      "metadata": {
        "id": "92uQaoM2GpfD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 가중치 설정\n",
        "num_0 = sum(y_train == 0)\n",
        "num_1 = sum(y_train == 1)\n",
        "scale_pos_weight = num_0 / num_1"
      ],
      "metadata": {
        "id": "OSgTMPZoGdJM"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1515809e-dfdb-4a8f-b6f2-804e09b3cef7",
        "id": "I2fQZAcfEPyF"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [06:15:06] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.87\n",
            "Validation F1 Score: 0.92\n",
            "Test Accuracy: 0.86\n",
            "Test F1 Score: 0.92\n",
            "\n",
            "Classification Report on Test Data:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.69      0.57       450\n",
            "           1       0.95      0.88      0.92      2850\n",
            "\n",
            "    accuracy                           0.86      3300\n",
            "   macro avg       0.72      0.79      0.74      3300\n",
            "weighted avg       0.88      0.86      0.87      3300\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
        "\n",
        "# XGBoost Classifier 학습\n",
        "xgb = XGBClassifier(random_state=42, scale_pos_weight=scale_pos_weight, use_label_encoder=False, eval_metric='logloss')\n",
        "xgb.fit(X_train, y_train)\n",
        "\n",
        "# 검증 데이터 평가\n",
        "y_val_pred = xgb.predict(X_val)\n",
        "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
        "val_f1 = f1_score(y_val, y_val_pred)\n",
        "\n",
        "print(f\"Validation Accuracy: {val_accuracy:.2f}\")\n",
        "print(f\"Validation F1 Score: {val_f1:.2f}\")\n",
        "\n",
        "# 테스트 데이터 평가\n",
        "y_test_pred = xgb.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "test_f1 = f1_score(y_test, y_test_pred)\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
        "print(f\"Test F1 Score: {test_f1:.2f}\")\n",
        "\n",
        "# 분류 보고서 출력\n",
        "print(\"\\nClassification Report on Test Data:\")\n",
        "print(classification_report(y_test, y_test_pred))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#클래스별 Accuracy 계산\n",
        "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
        "class_0_accuracy = conf_matrix[0, 0] / conf_matrix[0].sum()  # TP / (TP + FN) for class 0\n",
        "class_1_accuracy = conf_matrix[1, 1] / conf_matrix[1].sum()  # TP / (TP + FN) for class 1\n",
        "\n",
        "# 클래스별 Accuracy 출력\n",
        "print(f\"\\nTest Class 0 Accuracy: {class_0_accuracy:.2f}\")\n",
        "print(f\"Test Class 1 Accuracy: {class_1_accuracy:.2f}\")"
      ],
      "metadata": {
        "outputId": "92aaa64b-8104-4ea6-a12b-7ac4e36c5352",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4hN8cDaEPyF"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Class 0 Accuracy: 0.69\n",
            "Test Class 1 Accuracy: 0.88\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##LightGBM"
      ],
      "metadata": {
        "id": "1iBPI-pqEPyG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 가중치 설정\n",
        "num_0 = sum(y_train == 0)\n",
        "num_1 = sum(y_train == 1)\n",
        "scale_pos_weight = num_0 / num_1"
      ],
      "metadata": {
        "id": "kDHVq86pHHuN"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d9e2642-d6f7-4cc2-810f-c907fd9e6825",
        "id": "oCsV65MSEPyG"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Number of positive: 13300, number of negative: 2100\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004224 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 3345\n",
            "[LightGBM] [Info] Number of data points in the train set: 15400, number of used features: 15\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.863636 -> initscore=1.845827\n",
            "[LightGBM] [Info] Start training from score 1.845827\n",
            "Validation Accuracy: 0.85\n",
            "Validation F1 Score: 0.91\n",
            "Test Accuracy: 0.84\n",
            "Test F1 Score: 0.90\n",
            "\n",
            "Classification Report on Test Data:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.44      0.71      0.54       450\n",
            "           1       0.95      0.86      0.90      2850\n",
            "\n",
            "    accuracy                           0.84      3300\n",
            "   macro avg       0.69      0.78      0.72      3300\n",
            "weighted avg       0.88      0.84      0.85      3300\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# LightGBM Classifier\n",
        "lgbm = LGBMClassifier(random_state=42,scale_pos_weight=scale_pos_weight)\n",
        "lgbm.fit(X_train, y_train)\n",
        "\n",
        "# 검증 데이터 평가\n",
        "y_val_pred = lgbm.predict(X_val)\n",
        "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
        "val_f1 = f1_score(y_val, y_val_pred)\n",
        "\n",
        "print(f\"Validation Accuracy: {val_accuracy:.2f}\")\n",
        "print(f\"Validation F1 Score: {val_f1:.2f}\")\n",
        "\n",
        "# 테스트 데이터 평가\n",
        "y_test_pred = lgbm.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "test_f1 = f1_score(y_test, y_test_pred)\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
        "print(f\"Test F1 Score: {test_f1:.2f}\")\n",
        "\n",
        "# 분류 보고서 출력\n",
        "print(\"\\nClassification Report on Test Data:\")\n",
        "print(classification_report(y_test, y_test_pred))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#클래스별 Accuracy 계산\n",
        "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
        "class_0_accuracy = conf_matrix[0, 0] / conf_matrix[0].sum()  # TP / (TP + FN) for class 0\n",
        "class_1_accuracy = conf_matrix[1, 1] / conf_matrix[1].sum()  # TP / (TP + FN) for class 1\n",
        "\n",
        "# 클래스별 Accuracy 출력\n",
        "print(f\"\\nTest Class 0 Accuracy: {class_0_accuracy:.2f}\")\n",
        "print(f\"Test Class 1 Accuracy: {class_1_accuracy:.2f}\")"
      ],
      "metadata": {
        "outputId": "903bd1a4-8b32-4700-d0c8-8c4efd8482a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Qluye7bEPyG"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Class 0 Accuracy: 0.71\n",
            "Test Class 1 Accuracy: 0.86\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##catBoost"
      ],
      "metadata": {
        "id": "hD8KYoOIEPyG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 가중치 설정\n",
        "num_0 = sum(y_train == 0)\n",
        "num_1 = sum(y_train == 1)\n",
        "class_weights = [num_1 / num_0, 1.0]  # [weight for class 0, weight for class 1]"
      ],
      "metadata": {
        "id": "sldQ5QdRHUkL"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "892e6372-a5f7-43a6-8071-af32fcb907ca",
        "id": "0tQeokY-EPyG"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.86\n",
            "Validation F1 Score: 0.92\n",
            "Test Accuracy: 0.85\n",
            "Test F1 Score: 0.91\n",
            "\n",
            "Classification Report on Test Data:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.74      0.58       450\n",
            "           1       0.95      0.87      0.91      2850\n",
            "\n",
            "    accuracy                           0.85      3300\n",
            "   macro avg       0.71      0.80      0.74      3300\n",
            "weighted avg       0.89      0.85      0.87      3300\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# CatBoost Classifier\n",
        "catboost = CatBoostClassifier(random_state=42, class_weights=class_weights, verbose=0)  # verbose=0으로 출력 제한\n",
        "catboost.fit(X_train, y_train)\n",
        "\n",
        "# 검증 데이터 평가\n",
        "y_val_pred = catboost.predict(X_val)\n",
        "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
        "val_f1 = f1_score(y_val, y_val_pred)\n",
        "\n",
        "print(f\"Validation Accuracy: {val_accuracy:.2f}\")\n",
        "print(f\"Validation F1 Score: {val_f1:.2f}\")\n",
        "\n",
        "# 테스트 데이터 평가\n",
        "y_test_pred = catboost.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "test_f1 = f1_score(y_test, y_test_pred)\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
        "print(f\"Test F1 Score: {test_f1:.2f}\")\n",
        "\n",
        "# 분류 보고서 출력\n",
        "print(\"\\nClassification Report on Test Data:\")\n",
        "print(classification_report(y_test, y_test_pred))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#클래스별 Accuracy 계산\n",
        "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
        "class_0_accuracy = conf_matrix[0, 0] / conf_matrix[0].sum()  # TP / (TP + FN) for class 0\n",
        "class_1_accuracy = conf_matrix[1, 1] / conf_matrix[1].sum()  # TP / (TP + FN) for class 1\n",
        "\n",
        "# 클래스별 Accuracy 출력\n",
        "print(f\"\\nTest Class 0 Accuracy: {class_0_accuracy:.2f}\")\n",
        "print(f\"Test Class 1 Accuracy: {class_1_accuracy:.2f}\")"
      ],
      "metadata": {
        "outputId": "d470ddb5-c8f6-45f9-f778-7774b201092c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0iqUhdOEPyG"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Class 0 Accuracy: 0.74\n",
            "Test Class 1 Accuracy: 0.87\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##adaBoost"
      ],
      "metadata": {
        "id": "VgUg59OXEPyH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "\n",
        "# 가중치 계산\n",
        "sample_weights = compute_sample_weight(class_weight='balanced', y=y_train)"
      ],
      "metadata": {
        "id": "or6Aa_CFHmoS"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9e5ccd9-f702-4054-e12c-b78ca8753e38",
        "id": "DHugrkW-EPyH"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.76\n",
            "Validation F1 Score: 0.84\n",
            "Test Accuracy: 0.76\n",
            "Test F1 Score: 0.84\n",
            "\n",
            "Classification Report on Test Data:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.32      0.69      0.44       450\n",
            "           1       0.94      0.76      0.84      2850\n",
            "\n",
            "    accuracy                           0.76      3300\n",
            "   macro avg       0.63      0.73      0.64      3300\n",
            "weighted avg       0.86      0.76      0.79      3300\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# AdaBoost Classifier 사용\n",
        "abc = AdaBoostClassifier(random_state=42)\n",
        "abc.fit(X_train, y_train, sample_weight=sample_weights)\n",
        "\n",
        "# 검증 데이터 평가\n",
        "y_val_pred = abc.predict(X_val)\n",
        "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
        "val_f1 = f1_score(y_val, y_val_pred)\n",
        "\n",
        "print(f\"Validation Accuracy: {val_accuracy:.2f}\")\n",
        "print(f\"Validation F1 Score: {val_f1:.2f}\")\n",
        "\n",
        "# 테스트 데이터 평가\n",
        "y_test_pred = abc.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "test_f1 = f1_score(y_test, y_test_pred)\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
        "print(f\"Test F1 Score: {test_f1:.2f}\")\n",
        "\n",
        "# 분류 보고서 출력\n",
        "print(\"\\nClassification Report on Test Data:\")\n",
        "print(classification_report(y_test, y_test_pred))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#클래스별 Accuracy 계산\n",
        "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
        "class_0_accuracy = conf_matrix[0, 0] / conf_matrix[0].sum()  # TP / (TP + FN) for class 0\n",
        "class_1_accuracy = conf_matrix[1, 1] / conf_matrix[1].sum()  # TP / (TP + FN) for class 1\n",
        "\n",
        "# 클래스별 Accuracy 출력\n",
        "print(f\"\\nTest Class 0 Accuracy: {class_0_accuracy:.2f}\")\n",
        "print(f\"Test Class 1 Accuracy: {class_1_accuracy:.2f}\")"
      ],
      "metadata": {
        "outputId": "c1a785bc-7513-4efa-e07e-affcae3f88ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsMbP4wSEPyH"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Class 0 Accuracy: 0.69\n",
            "Test Class 1 Accuracy: 0.76\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}