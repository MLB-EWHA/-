{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1jW4SFTiN48fu0o7zICB_HlAUtl-ikK06",
      "authorship_tag": "ABX9TyNzqJMRaYC0xyt87vnfFyop",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cindyshin2211/Website_Fingerprinting_MLB/blob/%EC%8B%A0%EC%84%B1%ED%98%84/DecisionTree_RandomForest(monunmon)_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Decision Tree"
      ],
      "metadata": {
        "id": "hlxauQLJ15wm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiNF8GXx1miN",
        "outputId": "82516c49-2ee7-46fc-d856-61f67a21508e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label Distribution:\n",
            "Label\n",
            "1    19000\n",
            "0     3000\n",
            "Name: count, dtype: int64\n",
            "Validation Accuracy: 0.87\n",
            "Validation F1 Score: 0.92\n",
            "Test Accuracy: 0.87\n",
            "Test F1 Score: 0.92\n",
            "\n",
            "Classification Report on Test Data:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.49      0.50       450\n",
            "           1       0.92      0.93      0.92      2850\n",
            "\n",
            "    accuracy                           0.87      3300\n",
            "   macro avg       0.72      0.71      0.71      3300\n",
            "weighted avg       0.86      0.87      0.87      3300\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 필요한 라이브러리 불러오기\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# 데이터 로드\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/EWHA_machine_ learning/monunmon.csv\")  # CSV 파일 경로\n",
        "\n",
        "# 레이블 이진 분류를 위해 변환 (0~94 -> 1, -1 -> 0)\n",
        "data['Label'] = data['Label'].apply(lambda x: 1 if x >= 0 else 0)\n",
        "\n",
        "# 변환 결과 확인\n",
        "print(\"Label Distribution:\")\n",
        "print(data['Label'].value_counts())\n",
        "\n",
        "# 특성과 레이블 분리\n",
        "X = data.drop(columns=['Label'])  # 피처 데이터\n",
        "y = data['Label']  # 레이블 데이터\n",
        "\n",
        "# Train, Validation, Test 데이터 나누기\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
        "\n",
        "# 데이터 정규화 (Logistic Regression은 정규화된 데이터에서 더 잘 작동)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Decision Tree 모델 생성 및 학습\n",
        "model = DecisionTreeClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 검증 데이터 평가\n",
        "y_val_pred = model.predict(X_val)\n",
        "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
        "val_f1 = f1_score(y_val, y_val_pred)\n",
        "\n",
        "print(f\"Validation Accuracy: {val_accuracy:.2f}\")\n",
        "print(f\"Validation F1 Score: {val_f1:.2f}\")\n",
        "\n",
        "# 테스트 데이터 평가\n",
        "y_test_pred = model.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "test_f1 = f1_score(y_test, y_test_pred)\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
        "print(f\"Test F1 Score: {test_f1:.2f}\")\n",
        "\n",
        "# 분류 보고서 출력\n",
        "print(\"\\nClassification Report on Test Data:\")\n",
        "print(classification_report(y_test, y_test_pred))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#필요한 라이브러리 불러오기\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "# 데이터 로드\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/EWHA_machine_ learning/monunmon.csv\")  # 데이터셋 경로 입력\n",
        "data['Label'] = data['Label'].apply(lambda x: 1 if x >= 0 else 0)  # 이진 레이블 변환\n",
        "\n",
        "# 특성과 레이블 분리\n",
        "X = data.drop(columns=['Label'])  # 피처 데이터\n",
        "y = data['Label']  # 레이블 데이터\n",
        "\n",
        "# Train, Validation, Test 데이터 나누기\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
        "\n",
        "# 데이터 정규화\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "### 방법 1: 클래스 가중치 적용 ###\n",
        "print(\"=== DecisionTreeClassifier with Class Weights ===\")\n",
        "model_weighted =DecisionTreeClassifier(random_state=42, class_weight='balanced')\n",
        "model_weighted.fit(X_train, y_train)\n",
        "\n",
        "# 테스트 데이터 평가\n",
        "y_test_pred = model_weighted.predict(X_test)\n",
        "print(\"\\nClassification Report on Test Data (Class Weights):\")\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "\n",
        "### 방법 2: SMOTE를 이용한 오버샘플링 ###\n",
        "print(\"\\n=== DecisionTreeClassifier with SMOTE ===\")\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"Resampled Training Set Size (SMOTE):\", X_train_smote.shape)\n",
        "\n",
        "model_smote =DecisionTreeClassifier(random_state=42)\n",
        "model_smote.fit(X_train_smote, y_train_smote)\n",
        "\n",
        "# 테스트 데이터 평가\n",
        "y_test_pred_smote = model_smote.predict(X_test)\n",
        "print(\"\\nClassification Report on Test Data (SMOTE):\")\n",
        "print(classification_report(y_test, y_test_pred_smote))\n",
        "\n",
        "### 방법 3: 언더샘플링 ###\n",
        "print(\"\\n=== DecisionTreeClassifier with Undersampling ===\")\n",
        "undersampler = RandomUnderSampler(random_state=42)\n",
        "X_train_under, y_train_under = undersampler.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"Resampled Training Set Size (Undersampling):\", X_train_under.shape)\n",
        "\n",
        "model_under = DecisionTreeClassifier(random_state=42)\n",
        "model_under.fit(X_train_under, y_train_under)\n",
        "\n",
        "# 테스트 데이터 평가\n",
        "y_test_pred_under = model_under.predict(X_test)\n",
        "print(\"\\nClassification Report on Test Data (Undersampling):\")\n",
        "print(classification_report(y_test, y_test_pred_under))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQ7TU_Mp2ivt",
        "outputId": "e7456f99-cab4-4443-fcd4-6fd1945ce5eb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== DecisionTreeClassifier with Class Weights ===\n",
            "\n",
            "Classification Report on Test Data (Class Weights):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.45      0.48       450\n",
            "           1       0.91      0.93      0.92      2850\n",
            "\n",
            "    accuracy                           0.87      3300\n",
            "   macro avg       0.71      0.69      0.70      3300\n",
            "weighted avg       0.86      0.87      0.86      3300\n",
            "\n",
            "\n",
            "=== DecisionTreeClassifier with SMOTE ===\n",
            "Resampled Training Set Size (SMOTE): (26600, 15)\n",
            "\n",
            "Classification Report on Test Data (SMOTE):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.42      0.57      0.48       450\n",
            "           1       0.93      0.88      0.90      2850\n",
            "\n",
            "    accuracy                           0.83      3300\n",
            "   macro avg       0.67      0.72      0.69      3300\n",
            "weighted avg       0.86      0.83      0.84      3300\n",
            "\n",
            "\n",
            "=== DecisionTreeClassifier with Undersampling ===\n",
            "Resampled Training Set Size (Undersampling): (4200, 15)\n",
            "\n",
            "Classification Report on Test Data (Undersampling):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.30      0.74      0.42       450\n",
            "           1       0.95      0.72      0.82      2850\n",
            "\n",
            "    accuracy                           0.72      3300\n",
            "   macro avg       0.62      0.73      0.62      3300\n",
            "weighted avg       0.86      0.72      0.76      3300\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest"
      ],
      "metadata": {
        "id": "w6VhywBi4Ze4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 라이브러리 불러오기\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# 데이터 로드\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/EWHA_machine_ learning/monunmon.csv\")  # CSV 파일 경로\n",
        "\n",
        "# 레이블 이진 분류를 위해 변환 (0~94 -> 1, -1 -> 0)\n",
        "data['Label'] = data['Label'].apply(lambda x: 1 if x >= 0 else 0)\n",
        "\n",
        "# 변환 결과 확인\n",
        "print(\"Label Distribution:\")\n",
        "print(data['Label'].value_counts())\n",
        "\n",
        "# 특성과 레이블 분리\n",
        "X = data.drop(columns=['Label'])  # 피처 데이터\n",
        "y = data['Label']  # 레이블 데이터\n",
        "\n",
        "# Train, Validation, Test 데이터 나누기\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
        "\n",
        "# 데이터 정규화 (Logistic Regression은 정규화된 데이터에서 더 잘 작동)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Random Forest 모델 생성 및 학습\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 검증 데이터 평가\n",
        "y_val_pred = model.predict(X_val)\n",
        "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
        "val_f1 = f1_score(y_val, y_val_pred)\n",
        "\n",
        "print(f\"Validation Accuracy: {val_accuracy:.2f}\")\n",
        "print(f\"Validation F1 Score: {val_f1:.2f}\")\n",
        "\n",
        "# 테스트 데이터 평가\n",
        "y_test_pred = model.predict(X_test)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "test_f1 = f1_score(y_test, y_test_pred)\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
        "print(f\"Test F1 Score: {test_f1:.2f}\")\n",
        "\n",
        "# 분류 보고서 출력\n",
        "print(\"\\nClassification Report on Test Data:\")\n",
        "print(classification_report(y_test, y_test_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFHwlsU13Z09",
        "outputId": "6c541c8c-324c-4b08-c3d2-2cc74f65123a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label Distribution:\n",
            "Label\n",
            "1    19000\n",
            "0     3000\n",
            "Name: count, dtype: int64\n",
            "Validation Accuracy: 0.91\n",
            "Validation F1 Score: 0.95\n",
            "Test Accuracy: 0.91\n",
            "Test F1 Score: 0.95\n",
            "\n",
            "Classification Report on Test Data:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.38      0.52       450\n",
            "           1       0.91      0.99      0.95      2850\n",
            "\n",
            "    accuracy                           0.91      3300\n",
            "   macro avg       0.88      0.68      0.74      3300\n",
            "weighted avg       0.90      0.91      0.89      3300\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#필요한 라이브러리 불러오기\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "# 데이터 로드\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/EWHA_machine_ learning/monunmon.csv\")  # 데이터셋 경로 입력\n",
        "data['Label'] = data['Label'].apply(lambda x: 1 if x >= 0 else 0)  # 이진 레이블 변환\n",
        "\n",
        "# 특성과 레이블 분리\n",
        "X = data.drop(columns=['Label'])  # 피처 데이터\n",
        "y = data['Label']  # 레이블 데이터\n",
        "\n",
        "# Train, Validation, Test 데이터 나누기\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
        "\n",
        "# 데이터 정규화\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "### 방법 1: 클래스 가중치 적용 ###\n",
        "print(\"=== RandomForest with Class Weights ===\")\n",
        "model_weighted = RandomForestClassifier(random_state=42, class_weight=\"balanced\")\n",
        "model_weighted.fit(X_train, y_train)\n",
        "\n",
        "# 테스트 데이터 평가\n",
        "y_test_pred = model_weighted.predict(X_test)\n",
        "print(\"\\nClassification Report on Test Data (Class Weights):\")\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "\n",
        "### 방법 2: SMOTE를 이용한 오버샘플링 ###\n",
        "print(\"\\n=== RandomForest with SMOTE ===\")\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"Resampled Training Set Size (SMOTE):\", X_train_smote.shape)\n",
        "\n",
        "model_smote = RandomForestClassifier(random_state=42)\n",
        "model_smote.fit(X_train_smote, y_train_smote)\n",
        "\n",
        "# 테스트 데이터 평가\n",
        "y_test_pred_smote = model_smote.predict(X_test)\n",
        "print(\"\\nClassification Report on Test Data (SMOTE):\")\n",
        "print(classification_report(y_test, y_test_pred_smote))\n",
        "\n",
        "### 방법 3: 언더샘플링 ###\n",
        "print(\"\\n=== RandomForest with Undersampling ===\")\n",
        "undersampler = RandomUnderSampler(random_state=42)\n",
        "X_train_under, y_train_under = undersampler.fit_resample(X_train, y_train)\n",
        "\n",
        "print(\"Resampled Training Set Size (Undersampling):\", X_train_under.shape)\n",
        "\n",
        "model_under =  RandomForestClassifier(random_state=42)\n",
        "model_under.fit(X_train_under, y_train_under)\n",
        "\n",
        "# 테스트 데이터 평가\n",
        "y_test_pred_under = model_under.predict(X_test)\n",
        "print(\"\\nClassification Report on Test Data (Undersampling):\")\n",
        "print(classification_report(y_test, y_test_pred_under))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUAIGcLa4oHy",
        "outputId": "91ea8274-06ab-4fe4-d2eb-453e3407a6b8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== RandomForest with Class Weights ===\n",
            "\n",
            "Classification Report on Test Data (Class Weights):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.37      0.52       450\n",
            "           1       0.91      0.99      0.95      2850\n",
            "\n",
            "    accuracy                           0.90      3300\n",
            "   macro avg       0.87      0.68      0.73      3300\n",
            "weighted avg       0.90      0.90      0.89      3300\n",
            "\n",
            "\n",
            "=== RandomForest with SMOTE ===\n",
            "Resampled Training Set Size (SMOTE): (26600, 15)\n",
            "\n",
            "Classification Report on Test Data (SMOTE):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.64      0.62       450\n",
            "           1       0.94      0.93      0.94      2850\n",
            "\n",
            "    accuracy                           0.89      3300\n",
            "   macro avg       0.77      0.79      0.78      3300\n",
            "weighted avg       0.89      0.89      0.89      3300\n",
            "\n",
            "\n",
            "=== RandomForest with Undersampling ===\n",
            "Resampled Training Set Size (Undersampling): (4200, 15)\n",
            "\n",
            "Classification Report on Test Data (Undersampling):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.38      0.77      0.51       450\n",
            "           1       0.96      0.80      0.87      2850\n",
            "\n",
            "    accuracy                           0.80      3300\n",
            "   macro avg       0.67      0.79      0.69      3300\n",
            "weighted avg       0.88      0.80      0.82      3300\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "siOYZpz05MJn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}