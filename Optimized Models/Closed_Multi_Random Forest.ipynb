{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wDy0xdi-ZDUU"
   },
   "source": [
    "# 배깅- Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IZTqcVXya0uT"
   },
   "source": [
    "- 기본 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17163,
     "status": "ok",
     "timestamp": 1732774309902,
     "user": {
      "displayName": "오윤재",
      "userId": "04375251631092764589"
     },
     "user_tz": -540
    },
    "id": "jDhxA60F8Ukt",
    "outputId": "3f98809f-018f-4f59-e2f9-781fda59f4b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7739473684210526\n",
      "F1 Score (weighted): 0.7728213788787172\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        42\n",
      "           1       0.84      0.64      0.73        42\n",
      "           2       0.82      0.94      0.88        35\n",
      "           3       0.66      0.86      0.75        29\n",
      "           4       0.83      0.90      0.86        39\n",
      "           5       0.89      0.93      0.91        45\n",
      "           6       0.78      0.89      0.83        44\n",
      "           7       0.78      0.89      0.83        36\n",
      "           8       0.75      0.71      0.73        34\n",
      "           9       0.56      0.61      0.58        31\n",
      "          10       0.95      0.74      0.83        47\n",
      "          11       0.67      0.80      0.73        35\n",
      "          12       0.86      0.86      0.86        42\n",
      "          13       0.66      0.53      0.58        40\n",
      "          14       0.83      0.56      0.67        36\n",
      "          15       0.78      0.80      0.79        35\n",
      "          16       0.89      0.72      0.79        43\n",
      "          17       0.77      0.77      0.77        47\n",
      "          18       0.92      0.89      0.90        37\n",
      "          19       0.68      0.76      0.72        37\n",
      "          20       0.84      0.93      0.88        44\n",
      "          21       0.70      0.63      0.67        41\n",
      "          22       0.68      0.65      0.67        40\n",
      "          23       0.76      0.80      0.78        35\n",
      "          24       0.46      0.39      0.42        46\n",
      "          25       0.76      0.69      0.72        36\n",
      "          26       0.73      0.89      0.80        37\n",
      "          27       0.89      0.76      0.82        45\n",
      "          28       0.86      0.89      0.88        36\n",
      "          29       0.64      0.83      0.72        47\n",
      "          30       0.76      0.83      0.79        46\n",
      "          31       0.73      0.86      0.79        37\n",
      "          32       0.68      0.55      0.61        38\n",
      "          33       0.78      0.86      0.82        37\n",
      "          34       0.62      0.63      0.63        41\n",
      "          35       0.77      0.79      0.78        38\n",
      "          36       0.82      0.91      0.86        35\n",
      "          37       0.64      0.55      0.59        53\n",
      "          38       0.73      0.66      0.69        53\n",
      "          39       0.86      0.78      0.82        46\n",
      "          40       0.94      0.86      0.90        51\n",
      "          41       0.88      0.88      0.88        43\n",
      "          42       0.67      0.62      0.64        39\n",
      "          43       0.86      0.90      0.88        41\n",
      "          44       0.93      0.98      0.96        44\n",
      "          45       0.53      0.60      0.56        35\n",
      "          46       0.82      0.80      0.81        35\n",
      "          47       0.73      0.62      0.67        39\n",
      "          48       0.76      0.86      0.81        37\n",
      "          49       0.91      0.74      0.82        43\n",
      "          50       0.85      0.91      0.88        32\n",
      "          51       0.56      0.66      0.60        38\n",
      "          52       0.88      0.86      0.87        49\n",
      "          53       0.63      0.77      0.70        31\n",
      "          54       0.90      0.79      0.84        47\n",
      "          55       0.68      0.56      0.61        41\n",
      "          56       0.98      0.91      0.95        47\n",
      "          57       0.79      0.83      0.81        36\n",
      "          58       0.89      0.89      0.89        35\n",
      "          59       0.92      0.92      0.92        39\n",
      "          60       0.86      0.90      0.88        40\n",
      "          61       0.85      0.73      0.79        56\n",
      "          62       0.83      0.75      0.79        57\n",
      "          63       0.58      0.70      0.63        27\n",
      "          64       0.61      0.72      0.66        39\n",
      "          65       0.77      0.66      0.71        35\n",
      "          66       0.85      0.87      0.86        46\n",
      "          67       0.74      0.84      0.78        37\n",
      "          68       0.90      0.73      0.80        48\n",
      "          69       0.68      0.74      0.71        43\n",
      "          70       0.94      0.94      0.94        34\n",
      "          71       0.81      0.83      0.82        36\n",
      "          72       0.97      0.79      0.87        39\n",
      "          73       0.91      0.95      0.93        41\n",
      "          74       0.64      0.60      0.62        53\n",
      "          75       0.81      0.95      0.88        37\n",
      "          76       0.93      0.93      0.93        44\n",
      "          77       0.65      0.57      0.61        30\n",
      "          78       0.52      0.69      0.60        36\n",
      "          79       0.59      0.73      0.66        30\n",
      "          80       0.86      0.90      0.88        40\n",
      "          81       0.71      0.78      0.74        45\n",
      "          82       0.71      0.49      0.58        45\n",
      "          83       0.70      0.90      0.79        31\n",
      "          84       0.72      0.72      0.73        40\n",
      "          85       0.98      0.91      0.94        44\n",
      "          86       0.92      0.97      0.95        37\n",
      "          87       0.83      0.86      0.85        35\n",
      "          88       0.77      0.73      0.75        37\n",
      "          89       0.56      0.53      0.54        38\n",
      "          90       0.76      0.78      0.77        36\n",
      "          91       0.82      0.79      0.81        39\n",
      "          92       0.73      0.77      0.75        35\n",
      "          93       0.86      0.95      0.90        39\n",
      "          94       0.63      0.64      0.64        42\n",
      "\n",
      "    accuracy                           0.77      3800\n",
      "   macro avg       0.77      0.78      0.77      3800\n",
      "weighted avg       0.78      0.77      0.77      3800\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[28  0  0 ...  0  0  1]\n",
      " [ 0 27  3 ...  0  0  0]\n",
      " [ 0  0 33 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 27  0  0]\n",
      " [ 0  0  0 ...  0 37  0]\n",
      " [ 1  0  0 ...  0  0 27]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
    "import pandas as pd\n",
    "\n",
    "data=pd.read_csv('../mon.csv')\n",
    "\n",
    "# 특징(X)와 타겟(y) 분리\n",
    "X = data.drop(columns=['Label'])\n",
    "y = data['Label']\n",
    "\n",
    "# 데이터를 훈련 세트와 테스트 세트로 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 랜덤 포레스트 모델 초기화 및 학습\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 세트 예측\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 성능 평가\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')  # 가중 평균 F1 점수 계산\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score (weighted): {f1}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_rep)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0ZtCH_52a10F",
    "outputId": "bf1dedf2-1801-4e07-910d-a9be75e4571d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set: 13300 samples\n",
      "Validation Set: 2850 samples\n",
      "Test Set: 2850 samples\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "26 fits failed out of a total of 250.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 456, in fit\n",
      "    trees = Parallel(\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 65, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 127, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 190, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 959, in fit\n",
      "    super()._fit(\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 443, in _fit\n",
      "    builder.build(self.tree_, X, y, sample_weight, missing_values_in_feature_mask)\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 164, in sklearn.tree._tree.DepthFirstTreeBuilder.build\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 265, in sklearn.tree._tree.DepthFirstTreeBuilder.build\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 803, in sklearn.tree._tree.Tree._add_node\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 772, in sklearn.tree._tree.Tree._resize_c\n",
      "  File \"sklearn\\tree\\_utils.pyx\", line 37, in sklearn.tree._utils.safe_realloc\n",
      "MemoryError: could not allocate 3112960 bytes\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 456, in fit\n",
      "    trees = Parallel(\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 65, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 127, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 190, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 959, in fit\n",
      "    super()._fit(\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 443, in _fit\n",
      "    builder.build(self.tree_, X, y, sample_weight, missing_values_in_feature_mask)\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 164, in sklearn.tree._tree.DepthFirstTreeBuilder.build\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 265, in sklearn.tree._tree.DepthFirstTreeBuilder.build\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 803, in sklearn.tree._tree.Tree._add_node\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 772, in sklearn.tree._tree.Tree._resize_c\n",
      "  File \"sklearn\\tree\\_utils.pyx\", line 37, in sklearn.tree._utils.safe_realloc\n",
      "MemoryError: could not allocate 1556480 bytes\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 456, in fit\n",
      "    trees = Parallel(\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 65, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 127, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 190, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 959, in fit\n",
      "    super()._fit(\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 443, in _fit\n",
      "    builder.build(self.tree_, X, y, sample_weight, missing_values_in_feature_mask)\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 164, in sklearn.tree._tree.DepthFirstTreeBuilder.build\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 265, in sklearn.tree._tree.DepthFirstTreeBuilder.build\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 803, in sklearn.tree._tree.Tree._add_node\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 772, in sklearn.tree._tree.Tree._resize_c\n",
      "  File \"sklearn\\tree\\_utils.pyx\", line 37, in sklearn.tree._utils.safe_realloc\n",
      "MemoryError: could not allocate 778240 bytes\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 456, in fit\n",
      "    trees = Parallel(\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 65, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 127, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 190, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 959, in fit\n",
      "    super()._fit(\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 443, in _fit\n",
      "    builder.build(self.tree_, X, y, sample_weight, missing_values_in_feature_mask)\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 164, in sklearn.tree._tree.DepthFirstTreeBuilder.build\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 265, in sklearn.tree._tree.DepthFirstTreeBuilder.build\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 803, in sklearn.tree._tree.Tree._add_node\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 772, in sklearn.tree._tree.Tree._resize_c\n",
      "  File \"sklearn\\tree\\_utils.pyx\", line 37, in sklearn.tree._utils.safe_realloc\n",
      "MemoryError: could not allocate 6225920 bytes\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "7 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 456, in fit\n",
      "    trees = Parallel(\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 65, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 127, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 188, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 959, in fit\n",
      "    super()._fit(\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 443, in _fit\n",
      "    builder.build(self.tree_, X, y, sample_weight, missing_values_in_feature_mask)\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 164, in sklearn.tree._tree.DepthFirstTreeBuilder.build\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 265, in sklearn.tree._tree.DepthFirstTreeBuilder.build\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 803, in sklearn.tree._tree.Tree._add_node\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 772, in sklearn.tree._tree.Tree._resize_c\n",
      "  File \"sklearn\\tree\\_utils.pyx\", line 37, in sklearn.tree._utils.safe_realloc\n",
      "MemoryError: could not allocate 1556480 bytes\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 456, in fit\n",
      "    trees = Parallel(\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 65, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 127, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 188, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 959, in fit\n",
      "    super()._fit(\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 443, in _fit\n",
      "    builder.build(self.tree_, X, y, sample_weight, missing_values_in_feature_mask)\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 164, in sklearn.tree._tree.DepthFirstTreeBuilder.build\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 265, in sklearn.tree._tree.DepthFirstTreeBuilder.build\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 803, in sklearn.tree._tree.Tree._add_node\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 772, in sklearn.tree._tree.Tree._resize_c\n",
      "  File \"sklearn\\tree\\_utils.pyx\", line 37, in sklearn.tree._utils.safe_realloc\n",
      "MemoryError: could not allocate 3112960 bytes\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 456, in fit\n",
      "    trees = Parallel(\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 65, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 127, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 188, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 959, in fit\n",
      "    super()._fit(\n",
      "  File \"c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 443, in _fit\n",
      "    builder.build(self.tree_, X, y, sample_weight, missing_values_in_feature_mask)\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 164, in sklearn.tree._tree.DepthFirstTreeBuilder.build\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 265, in sklearn.tree._tree.DepthFirstTreeBuilder.build\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 803, in sklearn.tree._tree.Tree._add_node\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 772, in sklearn.tree._tree.Tree._resize_c\n",
      "  File \"sklearn\\tree\\_utils.pyx\", line 37, in sklearn.tree._utils.safe_realloc\n",
      "MemoryError: could not allocate 6225920 bytes\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\yzooz\\pythonenv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [0.7551433  0.73830037 0.58733837 0.74908415 0.76565754 0.76448316\n",
      "        nan 0.58732761 0.73830037 0.74999831        nan        nan\n",
      "        nan 0.58306528 0.74908415 0.73596778 0.75674123 0.59582008\n",
      " 0.74962686 0.73769684 0.75042641 0.75511093 0.75497559 0.75412087\n",
      " 0.75556981 0.72339785 0.7305605  0.74952331 0.75170488 0.76629584\n",
      " 0.74962686 0.76298923 0.76557303 0.7444262  0.73906985 0.73821295\n",
      " 0.58972201 0.75932666 0.59537772 0.74348748        nan        nan\n",
      "        nan 0.58967225 0.73441138        nan        nan        nan\n",
      " 0.58694012 0.74870965]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found: {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 20, 'bootstrap': True}\n",
      "\n",
      "Validation Accuracy: 0.7757894736842105\n",
      "Validation F1 Score: 0.7728641970586617\n",
      "\n",
      "Test Accuracy: 0.7929824561403509\n",
      "Test F1 Score: 0.7916543757618631\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.57      0.67        30\n",
      "           1       0.69      0.83      0.76        30\n",
      "           2       0.93      0.90      0.92        30\n",
      "           3       0.84      0.87      0.85        30\n",
      "           4       0.85      0.77      0.81        30\n",
      "           5       0.96      0.77      0.85        30\n",
      "           6       0.77      0.90      0.83        30\n",
      "           7       0.84      0.90      0.87        30\n",
      "           8       0.90      0.87      0.88        30\n",
      "           9       0.72      0.87      0.79        30\n",
      "          10       0.96      0.80      0.87        30\n",
      "          11       0.88      0.77      0.82        30\n",
      "          12       0.94      0.97      0.95        30\n",
      "          13       0.54      0.47      0.50        30\n",
      "          14       0.74      0.77      0.75        30\n",
      "          15       0.83      0.80      0.81        30\n",
      "          16       1.00      0.73      0.85        30\n",
      "          17       0.74      0.77      0.75        30\n",
      "          18       0.93      0.87      0.90        30\n",
      "          19       0.84      0.90      0.87        30\n",
      "          20       0.85      0.93      0.89        30\n",
      "          21       0.74      0.77      0.75        30\n",
      "          22       0.64      0.60      0.62        30\n",
      "          23       0.83      0.80      0.81        30\n",
      "          24       0.56      0.47      0.51        30\n",
      "          25       0.95      0.70      0.81        30\n",
      "          26       0.82      0.93      0.87        30\n",
      "          27       0.82      0.93      0.87        30\n",
      "          28       0.82      0.90      0.86        30\n",
      "          29       0.73      0.80      0.76        30\n",
      "          30       0.81      0.83      0.82        30\n",
      "          31       0.85      0.93      0.89        30\n",
      "          32       0.83      0.63      0.72        30\n",
      "          33       0.71      0.73      0.72        30\n",
      "          34       0.68      0.50      0.58        30\n",
      "          35       0.72      0.70      0.71        30\n",
      "          36       0.90      0.90      0.90        30\n",
      "          37       0.74      0.67      0.70        30\n",
      "          38       0.69      0.90      0.78        30\n",
      "          39       0.81      0.83      0.82        30\n",
      "          40       0.81      0.70      0.75        30\n",
      "          41       0.88      0.97      0.92        30\n",
      "          42       0.67      0.67      0.67        30\n",
      "          43       0.74      0.87      0.80        30\n",
      "          44       0.88      0.97      0.92        30\n",
      "          45       0.73      0.80      0.76        30\n",
      "          46       0.85      0.77      0.81        30\n",
      "          47       0.65      0.57      0.61        30\n",
      "          48       1.00      0.80      0.89        30\n",
      "          49       0.90      0.90      0.90        30\n",
      "          50       0.78      0.70      0.74        30\n",
      "          51       0.62      0.67      0.65        30\n",
      "          52       0.84      0.90      0.87        30\n",
      "          53       0.73      0.73      0.73        30\n",
      "          54       1.00      0.80      0.89        30\n",
      "          55       0.67      0.60      0.63        30\n",
      "          56       0.90      0.87      0.88        30\n",
      "          57       0.90      0.90      0.90        30\n",
      "          58       0.72      0.97      0.83        30\n",
      "          59       0.90      0.87      0.88        30\n",
      "          60       0.92      0.80      0.86        30\n",
      "          61       0.62      0.70      0.66        30\n",
      "          62       0.65      0.73      0.69        30\n",
      "          63       0.62      0.77      0.69        30\n",
      "          64       0.75      0.70      0.72        30\n",
      "          65       0.73      0.53      0.62        30\n",
      "          66       0.78      0.83      0.81        30\n",
      "          67       0.93      0.83      0.88        30\n",
      "          68       0.83      0.83      0.83        30\n",
      "          69       0.70      0.93      0.80        30\n",
      "          70       0.90      0.93      0.92        30\n",
      "          71       0.92      0.80      0.86        30\n",
      "          72       0.85      0.73      0.79        30\n",
      "          73       0.87      0.90      0.89        30\n",
      "          74       0.69      0.80      0.74        30\n",
      "          75       0.94      0.97      0.95        30\n",
      "          76       0.93      0.93      0.93        30\n",
      "          77       0.58      0.50      0.54        30\n",
      "          78       0.61      0.73      0.67        30\n",
      "          79       0.62      0.77      0.69        30\n",
      "          80       0.74      0.87      0.80        30\n",
      "          81       0.86      0.83      0.85        30\n",
      "          82       0.74      0.57      0.64        30\n",
      "          83       0.80      0.93      0.86        30\n",
      "          84       0.74      0.67      0.70        30\n",
      "          85       1.00      0.87      0.93        30\n",
      "          86       0.88      1.00      0.94        30\n",
      "          87       0.81      0.83      0.82        30\n",
      "          88       0.80      0.80      0.80        30\n",
      "          89       0.67      0.67      0.67        30\n",
      "          90       0.93      0.83      0.88        30\n",
      "          91       0.87      0.87      0.87        30\n",
      "          92       0.61      0.63      0.62        30\n",
      "          93       0.88      0.97      0.92        30\n",
      "          94       0.65      0.73      0.69        30\n",
      "\n",
      "    accuracy                           0.79      2850\n",
      "   macro avg       0.80      0.79      0.79      2850\n",
      "weighted avg       0.80      0.79      0.79      2850\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[17  0  0 ...  0  0  1]\n",
      " [ 0 25  0 ...  0  0  0]\n",
      " [ 0  1 27 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 19  0  1]\n",
      " [ 0  0  0 ...  0 29  0]\n",
      " [ 0  0  0 ...  0  0 22]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix, roc_curve, auc, precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# 특징(X)와 타겟(y) 분리\n",
    "X = data.drop(columns=['Label'])\n",
    "y = data['Label']\n",
    "\n",
    "# 데이터를 Train, Validation, Test로 나누기\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)  # 70% Train\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)  # 15% Validation, 15% Test\n",
    "\n",
    "# 랜덤 포레스트 모델 초기화\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# RandomizedSearchCV를 위한 하이퍼파라미터 공간 정의\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300, 500],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# RandomizedSearchCV 초기화 및 학습\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    scoring='f1_weighted'\n",
    ")\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 하이퍼파라미터 출력\n",
    "print(f\"Best parameters found: {random_search.best_params_}\")\n",
    "\n",
    "# 최적 하이퍼파라미터로 모델 생성\n",
    "best_model = RandomForestClassifier(random_state=42, **random_search.best_params_)\n",
    "\n",
    "# 최적 모델로 학습\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Validation Set으로 예측\n",
    "y_val_pred = best_model.predict(X_val)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "val_f1 = f1_score(y_val, y_val_pred, average='weighted')\n",
    "print(f\"\\nValidation Accuracy: {val_accuracy}\")\n",
    "print(f\"Validation F1 Score: {val_f1}\")\n",
    "\n",
    "# Test Set으로 예측\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
    "classification_rep = classification_report(y_test, y_test_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "print(f\"\\nTest Accuracy: {test_accuracy}\")\n",
    "print(f\"Test F1 Score: {test_f1}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_rep)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# ROC Curve 및 AUC 계산\n",
    "y_test_prob = best_model.predict_proba(X_test)[:, 1]  # 양성 클래스 확률\n",
    "fpr, tpr, _ = roc_curve(y_test, y_test_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f\"ROC curve (AUC = {roc_auc:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label=\"Random guess\")\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# PR Curve 및 AUC 계산\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_test_prob)\n",
    "pr_auc = auc(recall, precision)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(recall, precision, color='blue', lw=2, label=f\"PR curve (AUC = {pr_auc:.2f})\")\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall (PR) Curve')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pythonenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
