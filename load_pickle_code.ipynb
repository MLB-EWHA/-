{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6a7b3a0l2ep4"
   },
   "source": [
    "1. mon_standard.pkl > array code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "5mfwrTwPtd36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 19000\n",
      "Total samples: 19000\n",
      "Total samples: 19000\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "USE_SUBLABEL = False\n",
    "URL_PER_SITE = 10\n",
    "TOTAL_URLS   = 950\n",
    "\n",
    "# Load the pickle file\n",
    "\n",
    "with open(\"mon_standard.pkl\", 'rb') as fi: \n",
    "    data = pickle.load(fi)\n",
    "\n",
    "X1_mon = [] #타임스탬프 데이터를 저장할 배열\n",
    "X2_mon = [] #방향 * 크기 데이터를 저장할 배열\n",
    "y_mon = []  #레이블을 저장할 배열 (각 샘플이 어느 웹사이트에 속하는지가 표기될 예정)\n",
    "\n",
    "# 웹사이트와 인스턴스를 구분하여 저장하는 루프\n",
    "# x array (direction*timestamp), y array (site label)\n",
    "for i in range(TOTAL_URLS):\n",
    "    #레이블 할당 : 같은 웹사이트의 모든 하위 페이지에 동일한 레이블 부여\n",
    "    if USE_SUBLABEL:\n",
    "        label = i   #각 페이지에 고유한 레이블 부여\n",
    "    else:\n",
    "        label = i // URL_PER_SITE # Calculate which site's URL the current URL being processed belongs to and set that value as the label. Thus, URLs fetched from the same site are labeled identically.\n",
    "\n",
    "\n",
    "    #각 페이지의 샘플(트래픽 데이터 처리하기)\n",
    "    for sample in data[i]:   #해당 페이지의 모든 트래픽 샘플 반복\n",
    "        size_seq = []        #크기 데이터 저장 배열\n",
    "        time_seq = []        #타임스탬프 저장 배열\n",
    "\n",
    "        #각 트래픽 샘플의 패킷 처리\n",
    "        for c in sample:\n",
    "            dr = 1 if c > 0 else -1     #방향 결정 (양수 : 1, 음수 : -1)\n",
    "            time_seq.append(abs(c))     #절대값으로 타임스탬프 저장\n",
    "            size_seq.append(dr * 512)   #방향에 512를 곱해 크기 저장\n",
    "\n",
    "        #각 샘플의 데이터를 배열에 추가\n",
    "        X1_mon.append(time_seq)\n",
    "        X2_mon.append(size_seq)\n",
    "        y_mon.append(label)\n",
    "\n",
    "#전체 샘플 수 출력\n",
    "size1 = len(X1_mon)\n",
    "size2 = len(X2_mon)\n",
    "size3 = len(y_mon)\n",
    "print(f'Total samples: {size1}') # Output: 19000\n",
    "print(f'Total samples: {size2}') # Output: 19000\n",
    "print(f'Total samples: {size3}') # Output: 19000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yz5mat0w2dJy"
   },
   "source": [
    "2. unmon_standard10.pkl > array code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "IWfcIOZovSMl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 3000\n",
      "3000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pickle\n",
    "\n",
    "TOTAL_URLS = 3000  # total number in the dataset\n",
    "\n",
    "\n",
    "with open('unmon_standard10_3000.pkl', 'rb') as f:  # Path to unmon_standard10.pkl in Colab\n",
    "    x = pickle.load(f)\n",
    "\n",
    "size = len(x)\n",
    "print(f'Total samples: {size}')\n",
    "\n",
    "X1_unmon = [] # Array to store instances (timestamps) - 10,000 instances, e.g., [[0.0, 0.5, 3.4, ...], [0.0, 4.5, ...], [0.0, 1.5, ...], ... [... ,45.8]]\n",
    "X2_unmon = [] # Array to store instances (direction*size) - size information\n",
    "y_unmon=[]\n",
    "\n",
    "for i in range(TOTAL_URLS):\n",
    "    size_seq = []\n",
    "    time_seq = []\n",
    "\n",
    "    for c in x[i]:\n",
    "        dr = 1 if c > 0 else -1\n",
    "        time_seq.append(abs(c))\n",
    "        size_seq.append(dr * 512) # In the pickle file, there is no size information, so the conversion code is set to multiply by 512 uniformly.\n",
    "\n",
    "    X1_unmon.append(time_seq)\n",
    "    X2_unmon.append(size_seq)\n",
    "    y_unmon.append(-1)\n",
    "\n",
    "print(len(X1_unmon)) # Print the length of X1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitored features shape: (19000, 15)\n",
      "Unmonitored features shape: (3000, 15)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 피처 추출 함수 정의\n",
    "def extract_features(X1, X2):\n",
    "    features = []\n",
    "\n",
    "    for time_seq, size_seq in zip(X1, X2):\n",
    "        total_packets = len(time_seq)   \n",
    "        incoming_packets = sum(1 for s in size_seq if s > 0)\n",
    "        outgoing_packets = total_packets - incoming_packets\n",
    "        incoming_ratio = incoming_packets / total_packets\n",
    "        outgoing_ratio = outgoing_packets / total_packets\n",
    "\n",
    "        outgoing_order = [i for i, s in enumerate(size_seq) if s > 0]\n",
    "        outgoing_std = np.std(outgoing_order)\n",
    "        outgoing_mean = np.mean(outgoing_order)\n",
    "\n",
    "        packets_per_second = total_packets / (time_seq[-1] - time_seq[0] + 1e-9)\n",
    "\n",
    "        first_30_incoming = sum(1 for s in size_seq[:30] if s > 0)\n",
    "        first_30_outgoing = 30 - first_30_incoming\n",
    "\n",
    "        inter_arrival_times = np.diff(time_seq)\n",
    "        inter_arrival_mean = np.mean(inter_arrival_times)\n",
    "        inter_arrival_std = np.std(inter_arrival_times)\n",
    "\n",
    "        chunk_size = 20\n",
    "        concentration = [sum(1 for s in size_seq[i:i + chunk_size] if s > 0) \n",
    "                         for i in range(0, len(size_seq), chunk_size)]\n",
    "        concentration_mean = np.mean(concentration)\n",
    "        concentration_std = np.std(concentration)\n",
    "\n",
    "        alternative_concentration = [sum(size_seq[i:i + chunk_size]) \n",
    "                                     for i in range(0, len(size_seq), chunk_size)]\n",
    "        alternative_sum = sum(alternative_concentration)\n",
    "\n",
    "        feature_vector = [\n",
    "            total_packets, incoming_packets, outgoing_packets,\n",
    "            incoming_ratio, outgoing_ratio, outgoing_std,\n",
    "            outgoing_mean, packets_per_second, first_30_incoming,\n",
    "            first_30_outgoing, inter_arrival_mean, inter_arrival_std,\n",
    "            concentration_mean, concentration_std, alternative_sum\n",
    "        ]\n",
    "        features.append(feature_vector)\n",
    "\n",
    "    return np.array(features)\n",
    "\n",
    "# Monitored와 Unmonitored 데이터에서 피처 추출\n",
    "features_mon = extract_features(X1_mon, X2_mon)\n",
    "features_unmon = extract_features(X1_unmon, X2_unmon)\n",
    "\n",
    "print(f\"Monitored features shape: {features_mon.shape}\")\n",
    "print(f\"Unmonitored features shape: {features_unmon.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Total Packets  Incoming Packets  Outgoing Packets  Incoming Ratio  \\\n",
      "0         1421.0             121.0            1300.0        0.085151   \n",
      "1          518.0              80.0             438.0        0.154440   \n",
      "2         1358.0             118.0            1240.0        0.086892   \n",
      "3         1446.0             122.0            1324.0        0.084371   \n",
      "4         1406.0             115.0            1291.0        0.081792   \n",
      "\n",
      "   Outgoing Ratio  Outgoing Std  Outgoing Mean  Packets per Second  \\\n",
      "0        0.914849    515.483953     773.322314          140.138067   \n",
      "1        0.845560    139.231951     226.162500           50.984252   \n",
      "2        0.913108    472.735508     786.110169          122.232223   \n",
      "3        0.915629    513.916038     820.139344          108.233533   \n",
      "4        0.918208    503.993490     789.608696          132.142857   \n",
      "\n",
      "   First 30 Incoming  First 30 Outgoing  Inter-arrival Mean  \\\n",
      "0                9.0               21.0            0.007141   \n",
      "1                8.0               22.0            0.019652   \n",
      "2                7.0               23.0            0.008187   \n",
      "3                9.0               21.0            0.009246   \n",
      "4                8.0               22.0            0.007573   \n",
      "\n",
      "   Inter-arrival Std  Concentration Mean  Concentration Std  Alternative Sum  \\\n",
      "0           0.041168            1.680556           2.510126        -603648.0   \n",
      "1           0.163930            3.076923           3.011811        -183296.0   \n",
      "2           0.066661            1.735294           2.361565        -574464.0   \n",
      "3           0.047809            1.671233           2.183718        -615424.0   \n",
      "4           0.038760            1.619718           2.112113        -602112.0   \n",
      "\n",
      "   Label  \n",
      "0      0  \n",
      "1      0  \n",
      "2      0  \n",
      "3      0  \n",
      "4      0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 피처 이름 정의 (15개 피처)\n",
    "feature_names = [\n",
    "    \"Total Packets\", \"Incoming Packets\", \"Outgoing Packets\", \n",
    "    \"Incoming Ratio\", \"Outgoing Ratio\", \"Outgoing Std\", \n",
    "    \"Outgoing Mean\", \"Packets per Second\", \"First 30 Incoming\", \n",
    "    \"First 30 Outgoing\", \"Inter-arrival Mean\", \"Inter-arrival Std\", \n",
    "    \"Concentration Mean\", \"Concentration Std\", \"Alternative Sum\"\n",
    "]\n",
    "# X 데이터를 DataFrame으로 변환\n",
    "df = pd.DataFrame(features_mon, columns=feature_names)\n",
    "df[\"Label\"] = y_mon\n",
    "print(df.head())  # 데이터 확인\n",
    "\n",
    "# CSV 파일로 저장하기\n",
    "df.to_csv(\"mon.csv\", index=False, encoding=\"utf-8-sig\")  # index=False는 행 번호를 제외하고 저장하기 위함입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Monitored와 Unmonitored 데이터 병합\n",
    "X = np.vstack((features_mon, features_unmon))\n",
    "y = np.hstack((y_mon, y_unmon))\n",
    "\n",
    "print(f\"Total data shape: {X.shape}, Total labels: {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 피처 이름 정의 (15개 피처)\n",
    "feature_names = [\n",
    "    \"Total Packets\", \"Incoming Packets\", \"Outgoing Packets\", \n",
    "    \"Incoming Ratio\", \"Outgoing Ratio\", \"Outgoing Std\", \n",
    "    \"Outgoing Mean\", \"Packets per Second\", \"First 30 Incoming\", \n",
    "    \"First 30 Outgoing\", \"Inter-arrival Mean\", \"Inter-arrival Std\", \n",
    "    \"Concentration Mean\", \"Concentration Std\", \"Alternative Sum\"\n",
    "]\n",
    "\n",
    "# X 데이터를 DataFrame으로 변환\n",
    "df = pd.DataFrame(X, columns=feature_names)\n",
    "df[\"Label\"] = y\n",
    "print(df.head())  # 데이터 확인\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV 파일로 저장하기\n",
    "df.to_csv(\"monunmon.csv\", index=False, encoding=\"utf-8-sig\")  # index=False는 행 번호를 제외하고 저장하기 위함입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 히스토그램 생성 (x축, y축 레이블 추가 및 bin 조정)\n",
    "fig, axes = plt.subplots(5, 4, figsize=(20, 20))  # 5x4 그리드 생성\n",
    "fig.suptitle(\"Feature Distributions\", fontsize=24)  # 메인 제목 설정\n",
    "\n",
    "# 각 피처에 대해 히스토그램 생성\n",
    "for i, feature in enumerate(df.columns[:-1]):  # 마지막 열(Label)은 제외\n",
    "    ax = axes[i // 4, i % 4]  # 그리드 위치 계산\n",
    "    \n",
    "    # 히스토그램 생성\n",
    "    sns.histplot(data=df, x=feature, bins=50, ax=ax, kde=False)  # bins=50으로 더 촘촘하게\n",
    "    ax.set_title(feature, fontsize=14)  # 각 그래프의 제목 설정\n",
    "    ax.set_xlabel(f\"{feature} 값\", fontsize=12)  # x축 레이블 설정\n",
    "    ax.set_ylabel(\"빈도(Frequency)\", fontsize=12)  # y축 레이블 설정\n",
    "\n",
    "    # 특정 피처의 경우 x축 범위를 수동으로 설정 (예: 패킷 수가 큰 경우)\n",
    "    if feature in [\"Total Packets\", \"Incoming Packets\", \"Outgoing Packets\"]:\n",
    "        ax.set_xlim(0, 10000)  # 0~10,000 범위로 설정\n",
    "\n",
    "# 레이아웃 조정 (제목과 그래프가 겹치지 않게)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(100, 6))\n",
    "sns.boxplot(data=df, x=\"Label\", y=\"Total Packets\")\n",
    "plt.title(\"Total Packets by Label\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 피처 간 상관관계 계산\n",
    "corr_matrix = df.corr()\n",
    "\n",
    "# 히트맵 생성\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\n",
    "plt.title(\"Feature Correlation Heatmap\", fontsize=16)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "pythonenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
