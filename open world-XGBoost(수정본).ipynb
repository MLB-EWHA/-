{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ThDzT-QDdw4Z","executionInfo":{"status":"ok","timestamp":1732540915473,"user_tz":-540,"elapsed":24770,"user":{"displayName":"오윤재","userId":"04375251631092764589"}},"outputId":"9696dccb-a6af-4f4e-d2c6-282817bc6f2a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["#1. 필요한 라이브러리 불러오기\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from xgboost import XGBClassifier\n","from sklearn.metrics import classification_report, accuracy_score, f1_score\n","\n","#2. 데이터 로드\n","data = pd.read_csv(\"/content/drive/MyDrive/monunmon.csv\")  # CSV 파일 경로\n","\n","#3. 레이블 이진 분류를 위해 변환 (0~94 -> 1, -1 -> 0)\n","data['Label'] = data['Label'].apply(lambda x: 1 if x >= 0 else 0)\n","\n","#4. 변환 결과 확인\n","print(\"Label Distribution:\")\n","print(data['Label'].value_counts())\n","\n","#5. 특성과 레이블 분리\n","X = data.drop(columns=['Label'])  # 피처 데이터\n","y = data['Label']  # 레이블 데이터\n","\n","#6. Train, Validation, Test 데이터 나누기\n","X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n","X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n","\n","#7. 데이터 정규화 (XGBoost는 정규화가 필수는 아니지만, 일관성을 위해 적용)\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_val = scaler.transform(X_val)\n","X_test = scaler.transform(X_test)\n","\n","#8. XGBoost 모델 정의 및 학습\n","# `scale_pos_weight`를 사용하여 클래스 불균형 처리\n","scale_pos_weight = sum(y_train == 0) / sum(y_train == 1)\n","model = XGBClassifier(random_state=42, eval_metric=\"logloss\",\n","                      scale_pos_weight=scale_pos_weight, n_estimators=1000, learning_rate=0.1)\n","model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n","\n","#9. 검증 데이터 평가\n","y_val_pred = model.predict(X_val)\n","val_accuracy = accuracy_score(y_val, y_val_pred)\n","val_f1 = f1_score(y_val, y_val_pred)\n","\n","print(f\"Validation Accuracy: {val_accuracy:.2f}\")\n","print(f\"Validation F1 Score: {val_f1:.2f}\")\n","\n","#10. 테스트 데이터 평가\n","y_test_pred = model.predict(X_test)\n","test_accuracy = accuracy_score(y_test, y_test_pred)\n","test_f1 = f1_score(y_test, y_test_pred)\n","\n","print(f\"Test Accuracy: {test_accuracy:.2f}\")\n","print(f\"Test F1 Score: {test_f1:.2f}\")\n","\n","#11. 분류 보고서 출력\n","print(\"\\nClassification Report on Test Data:\")\n","print(classification_report(y_test, y_test_pred))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"myttgKRze4Nb","executionInfo":{"status":"ok","timestamp":1732541949694,"user_tz":-540,"elapsed":7721,"user":{"displayName":"오윤재","userId":"04375251631092764589"}},"outputId":"531dbd03-1707-4273-8517-9fb72b32ed70"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Label Distribution:\n","Label\n","1    19000\n","0     3000\n","Name: count, dtype: int64\n","Validation Accuracy: 0.90\n","Validation F1 Score: 0.94\n","Test Accuracy: 0.89\n","Test F1 Score: 0.94\n","\n","Classification Report on Test Data:\n","              precision    recall  f1-score   support\n","\n","           0       0.61      0.60      0.61       450\n","           1       0.94      0.94      0.94      2850\n","\n","    accuracy                           0.89      3300\n","   macro avg       0.77      0.77      0.77      3300\n","weighted avg       0.89      0.89      0.89      3300\n","\n"]}]},{"cell_type":"code","source":["#1. 필요한 라이브러리 불러오기\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import classification_report, accuracy_score, f1_score\n","from imblearn.over_sampling import SMOTE\n","from imblearn.under_sampling import RandomUnderSampler\n","from xgboost import XGBClassifier\n","\n","#2. 데이터 로드\n","data = pd.read_csv(\"/content/drive/MyDrive/monunmon.csv\")  # 데이터셋 경로 입력\n","data['Label'] = data['Label'].apply(lambda x: 1 if x >= 0 else 0)  # 이진 레이블 변환\n","\n","#3. 특성과 레이블 분리\n","X = data.drop(columns=['Label'])  # 피처 데이터\n","y = data['Label']  # 레이블 데이터\n","\n","#4. Train, Validation, Test 데이터 나누기\n","X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n","X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n","\n","#5. 데이터 정규화\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_val = scaler.transform(X_val)\n","X_test = scaler.transform(X_test)\n","\n","### 방법 1: 클래스 가중치 적용 ###\n","print(\"=== XGBoost with Class Weights ===\")\n","scale_pos_weight = sum(y_train == 0) / sum(y_train == 1)  # 클래스 가중치 계산\n","model_weighted = XGBClassifier(random_state=42, scale_pos_weight=scale_pos_weight,\n","                               eval_metric=\"logloss\", n_estimators=1000, learning_rate=0.1)\n","model_weighted.fit(X_train, y_train)\n","\n","# 검증 데이터 평가\n","y_val_pred = model_weighted.predict(X_val)\n","val_accuracy = accuracy_score(y_val, y_val_pred)\n","val_f1 = f1_score(y_val, y_val_pred)\n","print(f\"Validation Accuracy: {val_accuracy:.2f}\")\n","print(f\"Validation F1 Score: {val_f1:.2f}\")\n","\n","# 테스트 데이터 평가\n","y_test_pred = model_weighted.predict(X_test)\n","test_accuracy = accuracy_score(y_test, y_test_pred)\n","test_f1 = f1_score(y_test, y_test_pred)\n","print(f\"Test Accuracy: {test_accuracy:.2f}\")\n","print(f\"Test F1 Score: {test_f1:.2f}\")\n","\n","# 분류 보고서\n","print(\"\\nClassification Report on Test Data (Class Weights):\")\n","print(classification_report(y_test, y_test_pred))\n","\n","### 방법 2: SMOTE를 이용한 오버샘플링 ###\n","print(\"\\n=== XGBoost with SMOTE ===\")\n","smote = SMOTE(random_state=42)\n","X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n","\n","print(\"Resampled Training Set Size (SMOTE):\", X_train_smote.shape)\n","\n","model_smote = XGBClassifier(random_state=42, eval_metric=\"logloss\",\n","                            n_estimators=1000, learning_rate=0.1)\n","model_smote.fit(X_train_smote, y_train_smote)\n","\n","# 검증 데이터 평가\n","y_val_pred_smote = model_smote.predict(X_val)\n","val_accuracy_smote = accuracy_score(y_val, y_val_pred_smote)\n","val_f1_smote = f1_score(y_val, y_val_pred_smote)\n","print(f\"Validation Accuracy (SMOTE): {val_accuracy_smote:.2f}\")\n","print(f\"Validation F1 Score (SMOTE): {val_f1_smote:.2f}\")\n","\n","# 테스트 데이터 평가\n","y_test_pred_smote = model_smote.predict(X_test)\n","test_accuracy_smote = accuracy_score(y_test, y_test_pred_smote)\n","test_f1_smote = f1_score(y_test, y_test_pred_smote)\n","print(f\"Test Accuracy (SMOTE): {test_accuracy_smote:.2f}\")\n","print(f\"Test F1 Score (SMOTE): {test_f1_smote:.2f}\")\n","\n","# 분류 보고서\n","print(\"\\nClassification Report on Test Data (SMOTE):\")\n","print(classification_report(y_test, y_test_pred_smote))\n","\n","### 방법 3: 언더샘플링 ###\n","print(\"\\n=== XGBoost with Undersampling ===\")\n","undersampler = RandomUnderSampler(random_state=42)\n","X_train_under, y_train_under = undersampler.fit_resample(X_train, y_train)\n","\n","print(\"Resampled Training Set Size (Undersampling):\", X_train_under.shape)\n","\n","model_under = XGBClassifier(random_state=42, eval_metric=\"logloss\",\n","                            n_estimators=1000, learning_rate=0.1)\n","model_under.fit(X_train_under, y_train_under)\n","\n","# 검증 데이터 평가\n","y_val_pred_under = model_under.predict(X_val)\n","val_accuracy_under = accuracy_score(y_val, y_val_pred_under)\n","val_f1_under = f1_score(y_val, y_val_pred_under)\n","print(f\"Validation Accuracy (Undersampling): {val_accuracy_under:.2f}\")\n","print(f\"Validation F1 Score (Undersampling): {val_f1_under:.2f}\")\n","\n","# 테스트 데이터 평가\n","y_test_pred_under = model_under.predict(X_test)\n","test_accuracy_under = accuracy_score(y_test, y_test_pred_under)\n","test_f1_under = f1_score(y_test, y_test_pred_under)\n","print(f\"Test Accuracy (Undersampling): {test_accuracy_under:.2f}\")\n","print(f\"Test F1 Score (Undersampling): {test_f1_under:.2f}\")\n","\n","# 분류 보고서\n","print(\"\\nClassification Report on Test Data (Undersampling):\")\n","print(classification_report(y_test, y_test_pred_under))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ItGAtq2cgDDf","executionInfo":{"status":"ok","timestamp":1732541882017,"user_tz":-540,"elapsed":13067,"user":{"displayName":"오윤재","userId":"04375251631092764589"}},"outputId":"934b4f67-28bf-4301-c28a-517ef600653f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["=== XGBoost with Class Weights ===\n","Validation Accuracy: 0.90\n","Validation F1 Score: 0.94\n","Test Accuracy: 0.89\n","Test F1 Score: 0.94\n","\n","Classification Report on Test Data (Class Weights):\n","              precision    recall  f1-score   support\n","\n","           0       0.61      0.60      0.61       450\n","           1       0.94      0.94      0.94      2850\n","\n","    accuracy                           0.89      3300\n","   macro avg       0.77      0.77      0.77      3300\n","weighted avg       0.89      0.89      0.89      3300\n","\n","\n","=== XGBoost with SMOTE ===\n","Resampled Training Set Size (SMOTE): (26600, 15)\n","Validation Accuracy (SMOTE): 0.90\n","Validation F1 Score (SMOTE): 0.94\n","Test Accuracy (SMOTE): 0.89\n","Test F1 Score (SMOTE): 0.94\n","\n","Classification Report on Test Data (SMOTE):\n","              precision    recall  f1-score   support\n","\n","           0       0.59      0.66      0.62       450\n","           1       0.95      0.93      0.94      2850\n","\n","    accuracy                           0.89      3300\n","   macro avg       0.77      0.79      0.78      3300\n","weighted avg       0.90      0.89      0.89      3300\n","\n","\n","=== XGBoost with Undersampling ===\n","Resampled Training Set Size (Undersampling): (4200, 15)\n","Validation Accuracy (Undersampling): 0.82\n","Validation F1 Score (Undersampling): 0.89\n","Test Accuracy (Undersampling): 0.79\n","Test F1 Score (Undersampling): 0.87\n","\n","Classification Report on Test Data (Undersampling):\n","              precision    recall  f1-score   support\n","\n","           0       0.37      0.76      0.50       450\n","           1       0.95      0.80      0.87      2850\n","\n","    accuracy                           0.79      3300\n","   macro avg       0.66      0.78      0.68      3300\n","weighted avg       0.87      0.79      0.82      3300\n","\n"]}]}]}