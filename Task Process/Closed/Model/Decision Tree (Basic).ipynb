{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "asO0nQudwuk9"
   },
   "outputs": [],
   "source": [
    "# 라이브러리 임포트\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 데이터 로드\n",
    "data = pd.read_csv(\"../../../mon.csv\")\n",
    "\n",
    "# 특징(X)과 레이블(y) 분리\n",
    "X = data.iloc[:, :-1]  # 특징 (feature)들\n",
    "y = data.iloc[:, -1]   # 레이블 (0~94)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y0O5O_TNizqw"
   },
   "source": [
    "**튜닝을 하지 않은 기본 decision tree model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1110,
     "status": "ok",
     "timestamp": 1733061646850,
     "user": {
      "displayName": "오윤재",
      "userId": "04375251631092764589"
     },
     "user_tz": -540
    },
    "id": "kma7xgJEic-l",
    "outputId": "81bd2978-1c5e-4c72-e37e-94b8ea3883af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.6387\n",
      "F1 Score (Weighted): 0.6390\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.36      0.37        42\n",
      "           1       0.65      0.62      0.63        42\n",
      "           2       0.85      0.83      0.84        35\n",
      "           3       0.56      0.66      0.60        29\n",
      "           4       0.76      0.90      0.82        39\n",
      "           5       0.73      0.82      0.77        45\n",
      "           6       0.78      0.82      0.80        44\n",
      "           7       0.69      0.69      0.69        36\n",
      "           8       0.70      0.62      0.66        34\n",
      "           9       0.54      0.48      0.51        31\n",
      "          10       0.81      0.62      0.70        47\n",
      "          11       0.65      0.74      0.69        35\n",
      "          12       0.80      0.79      0.80        42\n",
      "          13       0.36      0.38      0.37        40\n",
      "          14       0.60      0.58      0.59        36\n",
      "          15       0.81      0.63      0.71        35\n",
      "          16       0.67      0.67      0.67        43\n",
      "          17       0.72      0.72      0.72        47\n",
      "          18       0.84      0.73      0.78        37\n",
      "          19       0.58      0.59      0.59        37\n",
      "          20       0.86      0.84      0.85        44\n",
      "          21       0.57      0.59      0.58        41\n",
      "          22       0.54      0.47      0.51        40\n",
      "          23       0.55      0.60      0.58        35\n",
      "          24       0.23      0.24      0.24        46\n",
      "          25       0.48      0.58      0.53        36\n",
      "          26       0.70      0.76      0.73        37\n",
      "          27       0.62      0.56      0.59        45\n",
      "          28       0.72      0.72      0.72        36\n",
      "          29       0.58      0.55      0.57        47\n",
      "          30       0.73      0.76      0.74        46\n",
      "          31       0.63      0.65      0.64        37\n",
      "          32       0.53      0.45      0.49        38\n",
      "          33       0.74      0.76      0.75        37\n",
      "          34       0.42      0.49      0.45        41\n",
      "          35       0.62      0.61      0.61        38\n",
      "          36       0.73      0.69      0.71        35\n",
      "          37       0.47      0.40      0.43        53\n",
      "          38       0.50      0.42      0.45        53\n",
      "          39       0.67      0.63      0.65        46\n",
      "          40       0.66      0.53      0.59        51\n",
      "          41       0.83      0.81      0.82        43\n",
      "          42       0.55      0.59      0.57        39\n",
      "          43       0.70      0.68      0.69        41\n",
      "          44       0.89      0.95      0.92        44\n",
      "          45       0.49      0.54      0.51        35\n",
      "          46       0.42      0.51      0.46        35\n",
      "          47       0.56      0.59      0.57        39\n",
      "          48       0.74      0.70      0.72        37\n",
      "          49       0.84      0.63      0.72        43\n",
      "          50       0.68      0.78      0.72        32\n",
      "          51       0.53      0.42      0.47        38\n",
      "          52       0.82      0.73      0.77        49\n",
      "          53       0.47      0.61      0.54        31\n",
      "          54       0.82      0.79      0.80        47\n",
      "          55       0.53      0.56      0.55        41\n",
      "          56       0.91      0.89      0.90        47\n",
      "          57       0.60      0.69      0.64        36\n",
      "          58       0.61      0.66      0.63        35\n",
      "          59       0.82      0.79      0.81        39\n",
      "          60       0.74      0.80      0.77        40\n",
      "          61       0.71      0.61      0.65        56\n",
      "          62       0.69      0.54      0.61        57\n",
      "          63       0.35      0.59      0.44        27\n",
      "          64       0.60      0.62      0.61        39\n",
      "          65       0.50      0.51      0.51        35\n",
      "          66       0.73      0.65      0.69        46\n",
      "          67       0.61      0.76      0.67        37\n",
      "          68       0.62      0.44      0.51        48\n",
      "          69       0.52      0.53      0.53        43\n",
      "          70       0.88      0.88      0.88        34\n",
      "          71       0.61      0.69      0.65        36\n",
      "          72       0.64      0.59      0.61        39\n",
      "          73       0.90      0.90      0.90        41\n",
      "          74       0.39      0.34      0.36        53\n",
      "          75       0.82      0.84      0.83        37\n",
      "          76       0.89      0.91      0.90        44\n",
      "          77       0.53      0.53      0.53        30\n",
      "          78       0.42      0.47      0.45        36\n",
      "          79       0.38      0.60      0.46        30\n",
      "          80       0.79      0.78      0.78        40\n",
      "          81       0.62      0.67      0.65        45\n",
      "          82       0.58      0.40      0.47        45\n",
      "          83       0.54      0.68      0.60        31\n",
      "          84       0.72      0.57      0.64        40\n",
      "          85       0.80      0.80      0.80        44\n",
      "          86       0.97      0.92      0.94        37\n",
      "          87       0.76      0.71      0.74        35\n",
      "          88       0.53      0.54      0.53        37\n",
      "          89       0.36      0.37      0.36        38\n",
      "          90       0.51      0.58      0.55        36\n",
      "          91       0.57      0.59      0.58        39\n",
      "          92       0.54      0.60      0.57        35\n",
      "          93       0.73      0.85      0.79        39\n",
      "          94       0.49      0.57      0.53        42\n",
      "\n",
      "    accuracy                           0.64      3800\n",
      "   macro avg       0.64      0.64      0.64      3800\n",
      "weighted avg       0.65      0.64      0.64      3800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 학습 데이터와 테스트 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Decision Tree 모델 생성 및 학습\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 예측 및 성능 평가\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 정확도 평가\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
    "\n",
    "# F1 Score 계산\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')  # 'weighted'는 클래스 불균형을 고려한 평균을 계산\n",
    "print(f\"F1 Score (Weighted): {f1:.4f}\")\n",
    "\n",
    "# Classification Report 출력\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
