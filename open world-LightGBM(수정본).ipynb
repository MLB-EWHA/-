{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NoeW2Vbqkqx_","executionInfo":{"status":"ok","timestamp":1732542452242,"user_tz":-540,"elapsed":23099,"user":{"displayName":"오윤재","userId":"04375251631092764589"}},"outputId":"5bf3a858-0ebb-4295-95b7-eb089abe6707"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["#1. 필요한 라이브러리 불러오기\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import classification_report, accuracy_score, f1_score\n","import lightgbm as lgb\n","\n","#2. 데이터 로드\n","data = pd.read_csv(\"/content/drive/MyDrive/monunmon.csv\")  # CSV 파일 경로\n","\n","#3. 레이블 이진 분류를 위해 변환 (0~94 -> 1, -1 -> 0)\n","data['Label'] = data['Label'].apply(lambda x: 1 if x >= 0 else 0)\n","\n","#4. 변환 결과 확인\n","print(\"Label Distribution:\")\n","print(data['Label'].value_counts())\n","\n","#5. 특성과 레이블 분리\n","X = data.drop(columns=['Label'])  # 피처 데이터\n","y = data['Label']  # 레이블 데이터\n","\n","#6. Train, Validation, Test 데이터 나누기\n","X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n","X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n","\n","#7. 데이터 정규화 (LightGBM은 정규화 필요 없음, 하지만 데이터 분포에 따라 적용)\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_val = scaler.transform(X_val)\n","X_test = scaler.transform(X_test)\n","\n","#8. LightGBM 모델 정의 및 학습\n","model = lgb.LGBMClassifier(random_state=42, n_estimators=1000, learning_rate=0.1, max_depth=-1)\n","model.fit(X_train, y_train)\n","\n","#9. 검증 데이터 평가\n","y_val_pred = model.predict(X_val)\n","val_accuracy = accuracy_score(y_val, y_val_pred)\n","val_f1 = f1_score(y_val, y_val_pred)\n","\n","print(f\"Validation Accuracy: {val_accuracy:.2f}\")\n","print(f\"Validation F1 Score: {val_f1:.2f}\")\n","\n","#10. 테스트 데이터 평가\n","y_test_pred = model.predict(X_test)\n","test_accuracy = accuracy_score(y_test, y_test_pred)\n","test_f1 = f1_score(y_test, y_test_pred)\n","\n","print(f\"Test Accuracy: {test_accuracy:.2f}\")\n","print(f\"Test F1 Score: {test_f1:.2f}\")\n","\n","#11. 분류 보고서 출력\n","print(\"\\nClassification Report on Test Data:\")\n","print(classification_report(y_test, y_test_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HB_cQbIKkoCq","executionInfo":{"status":"ok","timestamp":1732542972863,"user_tz":-540,"elapsed":4798,"user":{"displayName":"오윤재","userId":"04375251631092764589"}},"outputId":"458884da-82b5-4707-c54f-8d2581fcfd0e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Label Distribution:\n","Label\n","1    19000\n","0     3000\n","Name: count, dtype: int64\n","[LightGBM] [Info] Number of positive: 13300, number of negative: 2100\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003941 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 3345\n","[LightGBM] [Info] Number of data points in the train set: 15400, number of used features: 15\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.863636 -> initscore=1.845827\n","[LightGBM] [Info] Start training from score 1.845827\n","Validation Accuracy: 0.92\n","Validation F1 Score: 0.95\n","Test Accuracy: 0.91\n","Test F1 Score: 0.95\n","\n","Classification Report on Test Data:\n","              precision    recall  f1-score   support\n","\n","           0       0.80      0.45      0.58       450\n","           1       0.92      0.98      0.95      2850\n","\n","    accuracy                           0.91      3300\n","   macro avg       0.86      0.72      0.76      3300\n","weighted avg       0.90      0.91      0.90      3300\n","\n"]}]},{"cell_type":"code","source":["#1. 필요한 라이브러리 불러오기\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import classification_report, accuracy_score, f1_score\n","from imblearn.over_sampling import SMOTE\n","from imblearn.under_sampling import RandomUnderSampler\n","import lightgbm as lgb\n","\n","#2. 데이터 로드\n","data = pd.read_csv(\"/content/drive/MyDrive/monunmon.csv\")  # 데이터셋 경로 입력\n","data['Label'] = data['Label'].apply(lambda x: 1 if x >= 0 else 0)  # 이진 레이블 변환\n","\n","#3. 특성과 레이블 분리\n","X = data.drop(columns=['Label'])  # 피처 데이터\n","y = data['Label']  # 레이블 데이터\n","\n","#4. Train, Validation, Test 데이터 나누기\n","X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n","X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n","\n","#5. 데이터 정규화 (LightGBM은 정규화 불필요하지만 형식 유지)\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_val = scaler.transform(X_val)\n","X_test = scaler.transform(X_test)\n","\n","### 방법 1: 클래스 가중치 적용 ###\n","print(\"=== LightGBM with Class Weights ===\")\n","model_weighted = lgb.LGBMClassifier(random_state=42, class_weight='balanced', n_estimators=1000, learning_rate=0.1)\n","model_weighted.fit(X_train, y_train)\n","\n","# 검증 데이터 평가\n","y_val_pred_weighted = model_weighted.predict(X_val)\n","val_accuracy_weighted = accuracy_score(y_val, y_val_pred_weighted)\n","val_f1_weighted = f1_score(y_val, y_val_pred_weighted)\n","print(f\"Validation Accuracy: {val_accuracy_weighted:.2f}\")\n","print(f\"Validation F1 Score: {val_f1_weighted:.2f}\")\n","\n","# 테스트 데이터 평가\n","y_test_pred_weighted = model_weighted.predict(X_test)\n","test_accuracy_weighted = accuracy_score(y_test, y_test_pred_weighted)\n","test_f1_weighted = f1_score(y_test, y_test_pred_weighted)\n","print(f\"Test Accuracy: {test_accuracy_weighted:.2f}\")\n","print(f\"Test F1 Score: {test_f1_weighted:.2f}\")\n","\n","# 분류 보고서\n","print(\"\\nClassification Report on Test Data (Class Weights):\")\n","print(classification_report(y_test, y_test_pred_weighted))\n","\n","### 방법 2: SMOTE를 이용한 오버샘플링 ###\n","print(\"\\n=== LightGBM with SMOTE ===\")\n","smote = SMOTE(random_state=42)\n","X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n","\n","print(\"Resampled Training Set Size (SMOTE):\", X_train_smote.shape)\n","\n","model_smote = lgb.LGBMClassifier(random_state=42, n_estimators=1000, learning_rate=0.1)\n","model_smote.fit(X_train_smote, y_train_smote)\n","\n","# 검증 데이터 평가\n","y_val_pred_smote = model_smote.predict(X_val)\n","val_accuracy_smote = accuracy_score(y_val, y_val_pred_smote)\n","val_f1_smote = f1_score(y_val, y_val_pred_smote)\n","print(f\"Validation Accuracy: {val_accuracy_smote:.2f}\")\n","print(f\"Validation F1 Score: {val_f1_smote:.2f}\")\n","\n","# 테스트 데이터 평가\n","y_test_pred_smote = model_smote.predict(X_test)\n","test_accuracy_smote = accuracy_score(y_test, y_test_pred_smote)\n","test_f1_smote = f1_score(y_test, y_test_pred_smote)\n","print(f\"Test Accuracy: {test_accuracy_smote:.2f}\")\n","print(f\"Test F1 Score: {test_f1_smote:.2f}\")\n","\n","# 분류 보고서\n","print(\"\\nClassification Report on Test Data (SMOTE):\")\n","print(classification_report(y_test, y_test_pred_smote))\n","\n","### 방법 3: 언더샘플링 ###\n","print(\"\\n=== LightGBM with Undersampling ===\")\n","undersampler = RandomUnderSampler(random_state=42)\n","X_train_under, y_train_under = undersampler.fit_resample(X_train, y_train)\n","\n","print(\"Resampled Training Set Size (Undersampling):\", X_train_under.shape)\n","\n","model_under = lgb.LGBMClassifier(random_state=42, n_estimators=1000, learning_rate=0.1)\n","model_under.fit(X_train_under, y_train_under)\n","\n","# 검증 데이터 평가\n","y_val_pred_under = model_under.predict(X_val)\n","val_accuracy_under = accuracy_score(y_val, y_val_pred_under)\n","val_f1_under = f1_score(y_val, y_val_pred_under)\n","print(f\"Validation Accuracy: {val_accuracy_under:.2f}\")\n","print(f\"Validation F1 Score: {val_f1_under:.2f}\")\n","\n","# 테스트 데이터 평가\n","y_test_pred_under = model_under.predict(X_test)\n","test_accuracy_under = accuracy_score(y_test, y_test_pred_under)\n","test_f1_under = f1_score(y_test, y_test_pred_under)\n","print(f\"Test Accuracy: {test_accuracy_under:.2f}\")\n","print(f\"Test F1 Score: {test_f1_under:.2f}\")\n","\n","# 분류 보고서\n","print(\"\\nClassification Report on Test Data (Undersampling):\")\n","print(classification_report(y_test, y_test_pred_under))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-Q8BUSR1lc2m","executionInfo":{"status":"ok","timestamp":1732542856515,"user_tz":-540,"elapsed":10901,"user":{"displayName":"오윤재","userId":"04375251631092764589"}},"outputId":"a7fc2c4b-cee3-475e-fb88-a05feb72ae47"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["=== LightGBM with Class Weights ===\n","[LightGBM] [Info] Number of positive: 13300, number of negative: 2100\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002219 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 3345\n","[LightGBM] [Info] Number of data points in the train set: 15400, number of used features: 15\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n","[LightGBM] [Info] Start training from score -0.000000\n","Validation Accuracy: 0.91\n","Validation F1 Score: 0.95\n","Test Accuracy: 0.91\n","Test F1 Score: 0.95\n","\n","Classification Report on Test Data (Class Weights):\n","              precision    recall  f1-score   support\n","\n","           0       0.71      0.55      0.62       450\n","           1       0.93      0.96      0.95      2850\n","\n","    accuracy                           0.91      3300\n","   macro avg       0.82      0.76      0.78      3300\n","weighted avg       0.90      0.91      0.90      3300\n","\n","\n","=== LightGBM with SMOTE ===\n","Resampled Training Set Size (SMOTE): (26600, 15)\n","[LightGBM] [Info] Number of positive: 13300, number of negative: 13300\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003579 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 3825\n","[LightGBM] [Info] Number of data points in the train set: 26600, number of used features: 15\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n","Validation Accuracy: 0.90\n","Validation F1 Score: 0.94\n","Test Accuracy: 0.89\n","Test F1 Score: 0.94\n","\n","Classification Report on Test Data (SMOTE):\n","              precision    recall  f1-score   support\n","\n","           0       0.60      0.64      0.62       450\n","           1       0.94      0.93      0.94      2850\n","\n","    accuracy                           0.89      3300\n","   macro avg       0.77      0.79      0.78      3300\n","weighted avg       0.90      0.89      0.90      3300\n","\n","\n","=== LightGBM with Undersampling ===\n","Resampled Training Set Size (Undersampling): (4200, 15)\n","[LightGBM] [Info] Number of positive: 2100, number of negative: 2100\n","[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000973 seconds.\n","You can set `force_col_wise=true` to remove the overhead.\n","[LightGBM] [Info] Total Bins 3344\n","[LightGBM] [Info] Number of data points in the train set: 4200, number of used features: 15\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n","Validation Accuracy: 0.82\n","Validation F1 Score: 0.89\n","Test Accuracy: 0.79\n","Test F1 Score: 0.87\n","\n","Classification Report on Test Data (Undersampling):\n","              precision    recall  f1-score   support\n","\n","           0       0.38      0.78      0.51       450\n","           1       0.96      0.80      0.87      2850\n","\n","    accuracy                           0.79      3300\n","   macro avg       0.67      0.79      0.69      3300\n","weighted avg       0.88      0.79      0.82      3300\n","\n"]}]}]}